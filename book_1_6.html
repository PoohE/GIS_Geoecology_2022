<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>regression</title>
	<link rel="stylesheet" type="text/css" href="style.css">
	<style>
*{
  box-sizing: border-box;
}

figure {
    width: 50%; /* Ширина если надо расположить 2 картинки в ряд*/
    float: left; /* Выстраиваем элементы по горизонтали */
    margin: 0 0 0 0%; /* Отступ слева */
   text-indent: 0px; /* убираем отступ для картинки как ни странно */
   /* background: #f0f0f0; /* Цвет фона */
    border-radius: 1px; /* Радиус скругления */
    padding: 1%; /* Поля */
   }
   figure:first-child {
    margin-left: 0; /* Убираем отступ для первого элемента */
   }

picture {
 width: 33%; /* Ширина если надо расположить 3 картинки в ряд*/
    float: left; /* Выстраиваем элементы по горизонтали */
    margin: 0 0 0 0%; /* Отступ слева */
   text-indent: 0px; /* убираем отступ для картинки как ни странно */
   /* background: #f0f0f0; /* Цвет фона */
    border-radius: 1px; /* Радиус скругления */
    padding: 0%; /* Поля */
}
picture:first-child {
    margin-left: 0; /* Убираем отступ для первого элемента */
   }

   image {
    width: 100%; /* Ширина если надо расположить 1 картинки в ряд*/
    float: left; /* Выстраиваем элементы по горизонтали */
    margin: 0 0 0 0%; /* Отступ слева */
   text-indent: 0px; /* убираем отступ для картинки как ни странно */
   /* background: #f0f0f0; /* Цвет фона */
    border-radius: 1px; /* Радиус скругления */
    padding: 1%; /* Поля */
   }

</style>
</head>

<div class="sidenav">

	<a href="#h1">I. ОСНОВЫ ПРОСТРАНСТВЕННОГО АНАЛИЗА</a>

	<a href="#h2">6. РЕГРЕССИОННЫЙ АНАЛИЗ: ЛИНЕЙНАЯ И ГЕОГРАФИЧЕСКИ ВЗВЕШЕННАЯ РЕГРЕССИЯ</a>

	<a href="#h3_1">6.1. Регрессионный анализ: последовательность действий</a>
	<a href="#h3_2">6.2. Анализ Главных Компонент для выбора переменных</a>
	<a href="#h3_3">6.3. Исследовательская регрессия</a>
	<a href="#h3_4">6.4. OLS - Метод наименьших квадратов</a>
	<a href="#h3_5">6.5. Географически взвешенная регрессия</a>


	</div class="sidenav">

	<div class="content">

	<h1 id="h1">I. ОСНОВЫ ПРОСТРАНСТВЕННОГО АНАЛИЗА</h1>

	<h2 id="h2">6. РЕГРЕССИОННЫЙ АНАЛИЗ И ГЕОГРАФИЧЕСКИ ВЗВЕШЕННАЯ РЕГРЕССИЯ</h2>

			<h3 id="h3_1">6.1. Регрессионный анализ: последовательность действий</h3>


<p><strong>Регрессионный анализ</strong> - <span class="bolditalic">это способ выявления взаимосвязей между зависимой переменной и гипотетическими факторами, определяющими ее значение (состояние), которые в данной модели могут считаться независимыми объясняющими переменными</span>. После того, как мы подвергли наши данные о преступности в Нью-Йорке различным видам "испытаний" (отображение, выведение центрографических показателей, выяснение особенностей пространственного распределения и определение наличия и знака пространственной автокорреляции) можно  приступить к собственно поиску причинно-следственных связей, точнее, к их доказательству, поскольку отдельные аспекты зависимости между исследуемым феноменом и некоторыми переменными мы (отчасти) обнаружили в результате предшествующего анализа.</p>

<p>Последовательность такого рода моделирования причинно-следственных связей может выстраиваться различным образом - в зависимости от характера данных и поставленных задач. Более-менее обычная традиция диктует следующий порядок действий:</p>

<ol><li>Построение общей гипотезы исследования с выбором "предикторов" для модели;</li>
<li>Проверка переменных на коллинеарность, а модели в целом - на "переоснащение";</li>
<li>Проверка набора данных на наличие пропущенных значений;</li>
<li>Проверка набора данных на наличие выбросов значений, которые могут существенно исказить общую картину;</li>
<li>Проверка модели на необходимость включения "фиктивной" переменной;</li>
<li>Стандартизация и/или нормализация данных;</li>
<li>Выбор вида регрессионного анализа;</li>
<li>Осуществление Исследовательской Регрессии;</li>
<li>Интерпретация коэффициентов регрессии;</li>
<li>Перебор и выбраковка первичного набора объясняющих переменных;</li>
<li>Дополнительная диагностика посредством Метода Наименьших Квадратов (OLS);</li>
<li>Применение Географически Взвешенной Регрессии (GWR) для обработки пространственной неоднородности.</li></ol>

<p>Рассмотрим перечисленные шаги исследования более подробно.</p>
<p>На этапе <strong>Построение общей гипотезы исследования</strong> мы должны изложить максимально ясным образом свое представление о том, какие факторы могут влиять на состояние и поведение зависимой переменной. Хорошее подспорье для таких построений -  так называемые "ментальные карты", для разработки которых существует сегодня разнообразное программное обеспечение (например, <span class="blackbold">Microsoft Visio</span>), впрочем, вполне можно обойтись и рисованием обычных блок-схем карандашом на листе бумаги.</p>
<br>
<a id="CRIME"><img src="Pict_1_6/CRIME.png" width="80%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.1 Ментальная "карта" гипотезы факторов совершения тяжких преступлений против личности в Нью-Йорке</span>

<p>На схеме <a href="#CRIME">Рис. 6.1</a>  представлена гипотеза причинно-следственной связи для феномена "убийства" в Нью-Йорке (с опорой на имеющиеся и некоторые добавленные сведения). Разумеется - мы не являемся экспертами в данном вопросе и можем полагаться лишь на литературные данные <a href="BIBLIO.html#Grana_Windell_2017">[Grana, Windell, 2017]</a> и собственную интуицию. Исходя из наличных данных мы сделали следующие предположения (это именно предположения, лишенные пока какой-либо доказательной базы):<br>
<ol>
<li>Расовая принадлежность, возможно, является фактором, определяющим сравнительно большую или меньшую склонность к совершению преступлений;</li>
<li>Концентрация и возраст населения влияют на «атмосферу» преступности;</li>
<li>Вполне вероятно, что уровень образования в какой-то степени определяет девиантное поведение человека;</li>
<li>Низкие доходы домохозяйств вынуждают жителей к совершению преступлений;</li>
<li>Безработица является непосредственной причиной (даже поводом) преступности;</li>
<li>Различные морфотипы застройки могут благоприятствовать формированию «обстановки преступности»;</li>
<li>Повышение комфортности среды снижает преступность;</li>
<li>Заболевания могут служить поводом для совершения преступлений.</li></ol>
</p>

<p>Таким образом, в нашей гипотезе 8 потенциальных причин, каждая из которых может быть выражена двумя-тремя переменными. Например, интуитивно мы понимаем, что бедность может влиять на совершение преступлений, но понятие "бедность" в свою очередь описывается разными параметрами: общий уровень доходов (как самый общий показатель достатка/бедности), некий нижний уровень доходов (как показатель действительной нищеты) или, наконец,  выраженное неравенство доходов (как возможная причина зависти и мотивации к совершению преступления). Какой из этих параметров находится в наиболее тесной связи с зависимой переменной - заранее определить невозможно.</p>

<p><strong>Проверка модели на "переоснащение"</strong>. Изложенный выше пример с различными параметрами бедности  хорошо объясняет "соблазн" привлечения большого количества переменных: проще говоря, если вы имеете системное представление о феномене вам (естественно!) хочется "затащить" в модель все известные предикторы (ведь каждый из них предположительно своеобразно влияет на зависимую переменную). Однако подобное решение не безобидно в силу возможной <strong>коллинеарности</strong> показателей, которые могут параллельно и однообразно изменяться в пространстве, что приведет к эффекту  <strong>"переоснащения модели|model overfitting"</strong>.  <span class="bolditalic">Мультиколлинеарность существует между двумя или более переменными в наборе данных, когда они сильно коррелированы между собой, поэтому привлечение многих переменных, описывающих схожие (близкие) свойства изучаемого феномена, не обязательно приводит к созданию лучшей модели</span>.</p>

<p>Проверка переменных на коллинеарность может быть осуществлена разными способами. Можно сравнивать привлеченные факторы попарно, используя приемы <strong>Двумерного статистического анализа</strong> - <span class="monospace">Диаграммы рассеяния</span>, либо выстраивая <span class="monospace">Матрицы точечных диаграмм</span> для многих переменных одновременно. В многомерном анализе чаще используют <span class="blackbold">Principal Component Analysis|Анализ главных компонент</span> - метод, который уменьшает число факторов  до набора не связанных (или почти несвязанных) переменных, называемых <strong>основными компонентами</strong>, чтобы, с одной стороны, упростить интерпретацию, с другой - сохранить большую часть потенциально полезной информации.</p>

<p>Опыт геоинформационного моделирования свидетельствует, что, переоснащение чаще всего происходит, при нарушенном соотношении числа переменных и количества наблюдений, иными словами, если у нас, скажем, <span class="greencursiv">12</span> случаев заболеваний (изучаемый феномен), то не имеет смысла привлекать <span class="greencursiv">20</span> переменных для объяснения. Предлагается <a href="BIBLIO.html#de Vaus_2002">[de Vaus, 2002; </a><a href="BIBLIO.html#Tabachnick_et_al_2012">Tabachnick et al., 2012]</a> следовать  простым правилам, помогающим избежать перегрузки модели переменными:</p>

<ol>
    <li>При использовании множественной линейной регрессии отношение наблюдений к переменным должно быть больше 20 / 1;</li>
    <li>Размер выборки должен быть не менее 100 + k, где k - количество независимых переменных (факторов);</li>
    <li>В случае ненормально распределенной зависимой переменной, выборки должны быть еще увеличены.</li>
</ol>

<p>Эти эмпирические правила предназначены для общего руководства. Окончательное решение о выборе переменных должно приниматься в зависимости от рассматриваемой проблемы и имеющихся данных. <span class="bolditalic">Корректный подход заключается в том, чтобы изначально построить простую модель, объясняющую большую долю вариаций, а затем добавлять, менять или убирать переменные, добиваясь лучшего результата</span>.</p>

<p><strong>Недостающие значения</strong>. До первого запуска регрессионного анализа следует проверить существуют ли недостающие значения: в рассматриваемом случае с кварталами Нью-Йорка — это  кварталы, не несущие значений исследуемого явления (показателей преступности) и/или значений независимой переменной. Тремя наиболее распространенными способами устранения пропущенных значений являются: </p>
<ol>
	<li>Удаление наблюдений, содержащих пропущенные значения;</li>
	<li>Замена пропущенных значений переменной средним значением этой конкретной переменной;</li>
	<li>Заполнение пропущенных значений интерполяцией, например - с помощью простой линейной регрессии.</li>
</ol>

<p>В нашем случае нежилые кварталы Нью-Йорка, например - парковые территории  - не содержат данных о доходах домохозяйств или образовательном уровне населения, и хотя само изучаемое явление (преступность) на них "проецируется" - поскольку преступления (пусть и редкие) там все же зафиксированы, но  в рамках данной модели корректнее исключить их из анализа.</p>

<p>Проверка набора данных на наличие выбросов и <strong>Точек чрезмерного влияния|Leverage Points</strong> - также необходимый этап анализа. Свои выбросы может иметь любая из независимых переменных, привлеченных к анализу: если выбросы единичны в этом нет большой угрозы для моделирования. Хуже если выбросов много и гораздо хуже если выбросы двух или более переменных образуют общее скопление в пространстве ординации, что возможно, если переменные хотя бы частично взаимозависимы или имеют схожую пространственную автокорреляцию. В регрессионном анализе существует три подхода для обработки таких наблюдений:  </p>

<ol>
<li>Фиксация и удаление выбросов с помощью Анализа Кластеров и Выбросов до проведения регрессионного анализа;</li>
<li>Выполнение Множественной Линейной Регрессии (MLR), с включением всех данных, и созданием стандартизированного графика остатков, на котором можно проследить как выбросы, так и точки с чрезмерным влиянием. После удаления и тех и других можно снова протестировать модель -  если результаты будут улучшены,  следует отказаться от  наблюдений, содержащих выбросы и точки чрезмерного влияния;</li>
<li>Применение так называемой "робастной регрессии" - одного из приемов "надежной статистики".</li>
</ol>

<p><strong>Включение фиктивной переменной</strong>.  <span class="bolditalic">Фиктивная переменная|Dummy Variable это двоичная переменная, получающая значения <span class="greencursiv">1</span> или <span class="greencursiv">0</span>, указывающие на наличие <span class="greencursiv">(1)</span> или отсутствие <span class="greencursiv">(0)</span> некоторого категориального эффекта</span>. Целесообразность ее введения определяется гипотезой: например, если бы у нас были данные по гендерному составу лиц, совершающих преступления, то, возможно, имело бы смысл ввести эту переменную в модель: вполне вероятно, что убийства совершают не просто люди с низкими доходами и невысоким образовательным цензом, но, как правило, мужчины, следовательно, число именно таких лиц в квартале является значимым сочетанием обстоятельств. Такая переменная вводится как категориальная, например 0 - женский пол, 1 - мужской (или наоборот).</p>
<br>


<h3 id="h3_2">6.2. Анализ Главных Компонент для выбора переменных</h3>

<p><span class="bolditalic">Многомерные данные — это  данные с более чем двумя значениями, записанными для каждого наблюдения</span> <a href="BIBLIO.html#O’Sullivan_2010">[O'Sullivan, Unwin, 2010, p.316]</a>. Типичное представление многомерного набора данных <span class="monospace">A</span> с <span class="monospace">n</span> наблюдениями и <span class="monospace">p</span> переменными осуществляется через матрицу, в которой  столбцы представляют <span class="monospace">p </span>переменных, а строки представляют <span class="monospace">n</span> наблюдений. Многомерные данные существуют в многомерном пространстве, где число измерений равно числу переменных. Например, область тематического исследования с <span class="greencursiv">2108</span> жилыми кварталами Нью-Йорка  и <span class="greencursiv">20</span> переменными представляет собой <span class="greencursiv">p=20 </span>двадцатимерный набор данных, состоящий из <span class="greencursiv">n=2108 </span>наблюдений.</p>

<p><span class="blackbold">Анализ Главных Компонент|Principal Component Analysis (PCA)</span> — <span class="bolditalic">это метод, используемый для обобщения многомерных данных в меньшем количестве интерпретируемых переменных</span>. <span class="monospace">PCA</span> уменьшает размеры многомерного набора данных до набора независимых некоррелированных переменных, называемых  <strong>главными или основными компонентами</strong>, чтобы сделать анализ более полным и упростить интерпретацию, в то же время сохраняя большую часть информации (вариаций), существующей в наборе данных. <span class="bolditalic"><Основной компонент представляет собой линейную комбинацию исходных (или стандартизированных) значений переменных и рассчитывается путем извлечения собственных векторов и собственных значений матрицы дисперсии–ковариации или корреляционной матрицы.</p>

<p>Собственные векторы интерпретации извлекаются из матрицы дисперсии–ковариации и используются для построения новых осей, называемых главными компонентами, которые соответствуют направлению (в исходном пространстве) с наибольшей дисперсией данных <a href="BIBLIO.html#Hamilton_2014">[Hamilton, 2014]</a>.</p>

<p>Чтобы лучше понять, как работает алгоритм <span class="blackbold">Анализ Главных Компонент</span>, рассмотрим  конкретный пример. Предположим, мы исследуем с помощью линейной регрессии взаимосвязь между тяжкими преступлениями и долей афроамериканского населения в кварталах Нью-Йорка. Используя точечную диаграмму  двумерного пространства, построенную в <span class="blue">SAGA GIS</span>, мы получаем прямую линейной регрессии и формулу типа  <span class="greencursiv">y: a + b * x</span> для <span class="greencursiv">2108</span> кварталов (N):</p>

y: 7.36 + 0.019 * x <br>
<br>
<a id="SAGA_.crimelgy-afrsqrt"><img src="Pict_1_6/SAGA_.crimelgy-afrsqrt.png" width="70%" height="relative"></a>
<br>
<span class="imgtitle">Рис. 6.2 Диаграмма рассеяния для переменных Общая преступность - Доля афроамериканцев  в общей численности населения квартала</span>

<p>Мы можем рассчитать дисперсию <span class="monospace">σ2</span> в направлении <b>X</b> и дисперсию <span class="monospace">σ2</span> в направлении <b>Y</b> в качестве меры разброса значений. Тем не менее, горизонтальная и вертикальная дисперсия не совсем точно объясняет четкую диагональную тенденцию. Вместо вычисления дисперсии для осей <b>X</b> и <b>Y</b> лучше повернуть их так, чтобы ось <b>x</b> фиксировала максимальную дисперсию облака точек данных. Ось <b>Y</b> останется ортогональной к <b>X</b>, захватывая другую долю дисперсии. Новые оси являются первым и вторым основными компонентами, и, одновременно, это оси <span class="blackbold">Standard Deviational Ellipse|Эллипса стандартного отклонения</span> - одной из центрографических дистанционных характеристик распределения.</p>
<br>

<a id="SAGA_.crimelgy-afrsqrt"><img src="Pict_1_6/EllipsesStandrtDev_Afro.png" width="50%" height="relative"></a>
<br>
<span class="imgtitle">Рис. 6.3 Эллипсы стандартного отклонения для точек преступлений, совершенных афро-американцами (три эллипса соответствуют стандартному отклонению первого, второго и третьего порядков, охватывающих соответственно 68%, 95% и 99%  точек)

<p>Центр эллипса — это  средний центр точек данных. Главная ось лежит на первом компоненте, а второстепенная ось, которая ортогональна главной, лежит на втором компоненте. Длина каждой оси равна квадратному корню из соответствующего собственного значения. Угол поворота эллипса (указан в таблице слоя как <span class="monospace">Rotation</span>) и будет углом разворота  ортогональных осей.</p>

<p>В <span class="red">ArcMAP10.x</span> для того, чтобы использовать <span class="blackbold">Principal Component Analysis (PCA)</span> набора <span class="monospace">Multivariate</span> группы <span class="monospace">Spatial Analyst Tools</span> необходимо создать из векторного файла полигонов (кварталы Нью-Йорка) серию растров для каждой отдельной переменной и загрузить их потом в качестве растровых каналов (raster bands) генерируемого инструментом многоканального растра.</p>

<p>До проведения <span class="blackbold">PCA</span> целесообразно еще раз убедиться в отсутствии резких различий в диапазонах переменных, и провести (если необходимо) нормализацию или шкалирование данных <a href="#Таблица 6.1">(Таблица 6.1)</a>.</p>


<a id="Таблица 6.1"></a> <span class="imgtitle">Таблица 6.1 Трансформация данных, используемая для уменьшения асимметрии и нормализации данных

<div class="table">
<table id="customers">
        <table border="1">

<tr>
	<th>№</th>
<th>Наименование растра</th>
<th>Содержание<br> переменной</th>
<th>Преобразование исходного <br> значения</th>
</tr>

<tr>
<td>1</td>
<td>poorsqrt</td>
<td>доля домохозяйств ниже уровня бедности</td>
<td>нормализация</td>
</tr>

<tr>
<td>2</td>
<td>giniIndex</td>
<td>индекс Джини</td>
<td>нормализация</td>

</tr>
<tr>
<td>3</td>
<td>afrunmploysrt</td>
<td>доля афроамериканского безработного населения</td>
<td>нормализация</td>
</tr>

<tr>
<td>4</td>
<td>income</td>
<td>среднегодовой доход домохозяйств</td>
<td>шкалирование</td>
</tr>

<tr>
<td>5</td>
<td>unemploy</td>
<td>уровень безработицы</td>
<td>нормализация</td>

</tr>
<tr>
<td>6</td>
<td>bachprcnt</td>
<td>доля лиц со степенью бакалавра</td>
<td>-</td>
</tr>

<tr>
<td>7</td>
<td>medianage</td>
<td>средний возраст населения</td>
<td>-</td>
</tr>
<tr>
<td>8</td>
<td>popdnslg</td>
<td>плотность населения</td>
<td>нормализация</td>

</tr>
<tr>
<td>9</td>
<td>footprint</td>
<td>объемный след застройки</td>
<td>шкалирование</td>

</tr>
<tr>
<td>10</td>
<td>parcprcnt</td>
<td>доля парковых территорий</td>
<td>-</td>
</tr>

<tr>
<td>11</td>
<td>cancersqroot</td>
<td>число онкологических диагнозов</td>
<td>нормализация</td>
</tr>

</table>
<br>

<p>Следует иметь ввиду, что при загрузке растров в диалоговом окне <span class="blackbold">PCA</span> <span class="monospace">input raster bands</span> - вне зависимости от того, как вы это делаете - по одному или списком, захватив их в таблице слоев  <span class="monospace">Table of Content</span> - вверху списка окажутся слои, загруженные последними и скрипт пронумерует их именно в этой последовательности; это важно, потому что в выходных таблицах алгоритма <span class="monospace">PCA</span> значатся номера слоев (но не их названия).</p>

<p>На выходе PCA - многоканальный растр и файл отчета в формате txt, открывающийся обычным образом: <span class="monospace">Result >> RCM >> Output Data File: PCA.TXT.</span> Этот файл содержит пять разделов:</p>

<div class="script">	
Input raster(s) - отображает последовательность загрузки - верхний растр получает номер 1, нижний - последний номер (в нашем случае - 19)<br>
COVARIANCE MATRIX - матрица ковариации, является обобщением дисперсии (диагональные элементы ковариационной матрицы показывают дисперсии по изначальному базису, а ее собственные значения – по новому);<br>
CORRELATION MATRIX - матрица корреляции;<br>
EIGENVALUES AND EIGENVECTORS - айгензначения и значения айгенвекторов,<br>
PERCENT AND ACCUMULATIVE EIGENVALUES - процент объясненной вариабельности.<br>
</div>

<p>Для удобной работы с выводными данными <span class="blackbold">PCA </span>лучше скопировать таблицы каждого раздела в <span class="blackbold">Excel</span>, использовав при необходимости прием <span class="blackbold">разделение данных по столбцам</span> и не забывая преобразовать формат ячеек  в "числовой". После первого прогона инструмента необходимо зафиксировать "лишние" переменные, получившие высокий коэффициент в <span class="monospace">Матрице корреляции</span>. Для лучшей ориентировки можно заменить номера переменных названием исходных растров (если забыли порядок загрузки - смотрим в первых раздела TXT-отчета <span class="monospace">Input raster</span>).</p>

<a id="PCI_01_Corellation"><img src="Pict_1_6/PCI_01_Corellation.png" width="100%" height="80%"></a><br>

<span class="imgtitle">Рис. 6.4 Матрица корреляции Анализа Главных Компонент для 19 переменных (импортирована в Excel, ячейки с высокими коэффициентами корреляции затенены)</span>
<br>

<p>Далее ищем пары с высоким <span class="greencursiv">> 0,8</span>	 и значительным <span class="greencursiv"> > 0,5</span>	 коэффициентом корреляции (в нашем случае они вполне ожидаемы и объяснимы):<br></p>

<ul>
<li>buildsquare (площадь занимаемая суммой оснований зданий и сооружений) и footprint (объемный индекс застроенности, совокупная площадь с учетом этажности);</li>
<li>onlyhighscool (лица со школьным образованием) и onlybachel (лица со степенью бакалавра);</li>
<li>onlybachel (лица со степенью бакалавра) и doctorate (лица со степенью PhD);</li>
<li>afroprcnt (доля афроамериканского населения) и afrunempl (доля безработного афроамериканского населения);</li>
<li>otherethnic (доля иных этносов, т.е., не белого и не афроамериканского населения) и verypoor (процент беднейших домохозяйств);</li>
<li>european (доля европейского населения) и onlybachel  (лица со степенью бакалавра);</li>
<li>byciclelength (длина велосипедных дорожек) и parkarea (площадь парков)
waterarea (лощадь акваторий) и parkarea (площадь парков).</li>
</ul>

<p>Таким образом модель явно переоснащена и можно без ущерба для корректности избавиться от восьми переменных, выбирая из пары связанных "лучшие" (с большим коэффициентом детерминации на парных графиках с зависимой переменной - преступностью) переменные. В качестве <b>показателя застроенности</b> оставляем <span class="monospace">объемный индекс</span>, (учитывающий и высоту зданий) и убираем <span class="monospace">площадь оснований зданий и сооружений</span>; в группе, характеризующей <b>уровень образования</b> избавляемся от <span class="monospace">школьной ступени</span>  и от <span class="monospace">доктората</span>; выбираем как более точную переменную <span class="monospace">безработного афроамериканского населения</span> (избавляемся от <span class="monospace">доли  афроамериканского населения</span>), также убираем еще один этнический признак - <span class="monospace">otherethnic|иные этносы</span>, т.к., он косвенно отражается в показателе <span class="monospace">verypoor|беднейшие домохозяйства</span></b>, также убираем и <span class="monospace">долю белого населения</span>, ибо оно достаточно жестко связано с <span class="monospace">долей лиц с бакалаврским дипломом</span>. Все три показателя <b>комфортности среды</b> оказались тесно связанными, поэтому целесообразно избавиться от <span class="monospace">длины велодорожек</span> и <span class="monospace">площади акваторий</span>, которая зависит от <span class="monospace">площади парков</span>.</p>

<p>Следующий запуск алгоритма <span class="blackbold">PCA</span> проводим  для сокращенного списка из 11 переменных, загружая их в порядке предварительного представления об их значимости. Полученная для 11 переменных <span class="monospace">Матрица Корреляции</span>, с одной стороны, уже свободна от  связанных между собой пар факторов, с другой - содержит не ничтожные коэффициенты (значение R<sup>2</sup> около <span class="greencursiv">+0,3</span> или <span class="greencursiv">- 0,3</span>): обстоятельство, сохраняющее  перспективы для поиска значимых связей между зависимой переменной и предикторами.</p>
<br>

<a id="PCI_02_Corellation"><img src="Pict_1_6/PCI_02_Corellation.png" width="80%" height="relative"></a><br>

<span class="imgtitle">Рис. 6.5 Матрица корреляции Анализа Главных Компонент для 11 переменных (затенены ячейки с "перспективными" для регрессионного анализа значениями)

<p>Следует обратить внимание и на другие разделы отчета <span class="blackbold">PCA-анализа</span>, содержащиеся в TXT-файле. Первый раздел отчета - <span class="monospace">Матрица Ковариации</span> - содержит величину <b>дисперсии признаков по диагонали</b> (<span class="monospace">дисперсия одномерной величин</span>ы), а в остальных ячейках – ковариации соответствующих пар признаков (<b>ковариации двух признаков</b>); в силу симметричности ковариации матрица тоже будет симметрична.</p>
<br>

<a id="PCI_02_Covariation"><img src="Pict_1_6/PCI_02_Covariation.png" width="80%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.6 Матрица ковариации Анализа Главных Компонент для 11 переменных (затенены  диагональные ячейки с величиной дисперсии для каждой переменной)

<p>По <span class="monospace">Матрице ковариации</span> можно выделить переменные с большим значением дисперсии - в нашем случае это <span class="monospace">Домохозяйства ниже уровня бедности, Средний доход домохозяйств, Удельная площадь парковых территорий</span>.</p>

<p>Третий раздел TXT-отчета <span class="blackbold">PCA-анализа</span> хранит айгенпары - <span class="monospace">Собственные Вектора|Eigenvectors и Айгензначения|Eigenvalues</span>. Айгенвекторы совпадают с эллипсом  радиусом в две сигмы, т.е., содержат в себе <span class="greencursiv">95%</span> всех наблюдений.</p>
<br>

<a id="PCI_02_Eigenvectors"><img src="Pict_1_6/PCI_02_Eigenvectors.png" width="80%" height="relative"></a><br>

<span class="imgtitle">Рис. 6.7 Скриншот Таблицы Собственные векторы (затененные ячейки диагонали) и парные Айгенвекторы  для 11 переменных 

<p><span class="monospace">Айгензначения</span> и <span class="monospace">Айгенвекторы</span> должны служить ориентиром для решения основного вопроса  - выбора переменных, которые будут задействованы в последующем регрессионном анализе. <span class="bolditalic">Чем больше собственное значение <span class="monospace">Eigenvalue</span>, тем более значимым является компонент, поскольку он отражает большую часть изменчивости исходных данных</span>. Как можно видеть по таблице <a href="#PCI_02_Eigenvectors">(Рис. 6.7)</a> в данном случае высокие айгензначения характерны для первых шести компонентов <span class="monospace">(Число хозяйств ниже уровня бедности, Индекс Джини, Число безработных афроамериканцев, Общий уровень безработицы, Доля лиц со степенью бакалавра)</span>. Можем ли мы отбросить остальные переменные?</p>

<p>Ответ на этот вопрос не так прост. <span class="bolditalic">Поскольку каждое собственное айгензначение представляет дисперсию связанного ряда оценок основных компонентов, целесообразно сохранить наименьшее количество основных компонентов, которые объясняют желаемую долю общей дисперсии</span>. Именно так - с меньшим количеством измерений возможно охватить большую часть изменчивости и информации в данном наборе данных. Существует множество различных способов определения количества значимых компонентов, которые необходимо сохранить,  три наиболее используемых метода на практике включают:</p>

<ol>
<li>Правило "предельно низкой величины айгензначения",</li>
<li>Совокупный (накопленный) процент от общей дисперсии,</li>
<li>Построение  Scree-графика.</li>
</ol>


<p><strong>Правила предельно низкой величины айгензначения</strong> введены разными исследователями в качестве ориентировочных  рекомендуемых пороговых величин eigenvalues|айгензначения. Так, <strong>правило Кайзера</strong>, предусматривает  сохранение только одной главной переменной из числа тех, чье айгензначение не превышает <span class="greencursiv">1,0</span>. Аналогичное <strong>правило Джоллифа</strong> <a href="BIBLIO.html#Jolliffe_2002">[Jolliffe, 2002]</a>, устанавливает пороговое значение несколько ниже - <span class="greencursiv">0,7</span> обуславливая это необходимостью учета влияния дисперсии выборки (из-за возможных ошибок выборки).  В нашем случае это правило "спасает" седьмую переменную - <span class="monospace">Средний возраст жителей</span>.</p>

<p>Более интересный подход связан с построением  <span class="blackbold">Scree-графика</span> по данным последней таблицы (пятой части <span class="monospace">TXT-отчета</span> алгоритма <span class="blackbold">PCA</span>)  <span class="monospace">PERCENT AND ACCUMULATIVE EIGENVALUES</span>.</p>	

<a id="PCI_02_EigenPercents"><img src="Pict_1_6/PCI_02_EigenPercents.png" width="50%" height="relative"></a><br>

<span class="imgtitle">Рис. 6.8 Скриншот таблицы "Проценты и накопленные айгензначения" для 11 переменных </span>

<p>Таблица приводит абсолютные айгензначения и расчет процента общей дисперсии для каждого компонента <a href="#CI_02_EigenPercents">(Рис. 6.8)</a>; в последнем столбце - накопленный процент объясненной дисперсии (суммарное значение - <span class="greencursiv">100%</span>). Очевидно, что в данном случае накопленное значение достигает <span class="greencursiv">95%</span> уже для трех главных компонент (<span class="monospace">Число хозяйств ниже уровня бедности, Индекс Джини, Число безработных афроамериканцев</span>), на остальные 8 факторов приходится только <span class="greencursiv">5%</span> общей дисперсии.</p>

<p>Для более наглядного изображения можно построить график, где по горизонтали - номера главных компонент (начиная от 1-й), по вертикали - накопленный (ACCUMULATIVE) процент дисперсии, так называемый <span class="monospace">Scree Graf</span>.</p>
<br>

<a id="PCI_02_Scree_Graf"><img src="Pict_1_6/PCI_02_Scree_Graf.png" width="60%" height="relative"></a><br>

<span class="imgtitle">Рис. 6.9 Scree Graf, изображающий Накопленные айгензначения для 11 переменных 

<p> Название <span class="monospace">Scree Graf|График Осыпи</span> происходит от сходства типичной формы с формой осыпи у подножия склона; критичной здесь является точка перелома графика отделяющая "склон" от субгоризонтального "плато" -  в данном случае это точка пятой переменной (<b>безработные  афроамериканцы</b>).</p>

<p>Подытоживая отметим: <span class="bolditalic">с одной стороны, большинство методов, предложенных для определения оптимального количества основных компонентов, подвергаются критике за эвристичность и субъективность, с другой - широко признается, что принятие окончательного решения остается за экспертом, выстраивающим геоинформационную модель</span>. Так, <b>Л. Феррье</b> <a href="BIBLIO.html#Ferr´e_1995">[Ferr´e, 1995]</a>, например, например, делает вывод, что не существует идеального решения, которое отвечало бы всем целям исследования, в то время как <b>И.Т. Джоллифф</b> <a href="BIBLIO.html#Jolliffe_2002">[Jolliffe, 2002]</a> вообще полагает, что основанные на статистике процедуры, по-видимому, не дают явных преимуществ по сравнению с суждениями опытных экспертов, хорошо знающих предметную область модели.</p>
<br>


	<h3 id="h3_3">6.3. Исследовательская регрессия</h3>

<p><span class="blackbold">Исследовательская Регрессия (ИР)|Exploratory Regression (ER)</span> - <span class="bolditalic">это инструмент интеллектуального анализа данных, алгоритм, применяющий регрессию Метод Наименьших Квадратов (OLS) ко многим различным моделям, чтобы, выбрать те, которые проходят все необходимые диагностические тесты</span>. Путем тестирования всех доступных моделей <span class="monospace">Исследовательская регрессия</span> позволяет обнаружить независимые переменные, которые являются статистически значимыми в большинстве протестированных моделей. Для оценки результатов <span class="monospace">ИР</span> и проверки нарушены ли допущения регрессии используются специальные тесты <a href="BIBLIO.html#Bajjali_2018">[Bajjali_2018]</a>.</p>

<p>Связь между зависимой переменной и предикторами (переменными-факторами), которую мы пытаемся установить с помощью линейной регрессии, гипотетически выглядит следующим образом:</p>

Y: β<sub>0</sub> + β<sub>1</sub>*X<sub>1</sub> + β<sub>2</sub>*X<sub>2</sub> + β<sub>3</sub>*X<sub>3</sub> .... β<sub>i</sub>*X<sub>i</sub> + ε <br>

где:<br> 
Y - зависимая переменная (число убийство в квартале за 15 лет);<br>
X - объясняющие|explanatory переменные (доход, индекс Джини, средний возраст и т.д.);<br>
β - коэффициенты "бета", рассчитанные алгоритмом и выражающие силу и знак взаимосвязи между зависимой переменной и объясняющими переменными;<br>
знак (+/-), связанный с коэффициентом (по одному для каждой объясняющей переменной), указывает, является ли связь положительной или отрицательной;<br>
ε - остатки (residuals) или часть зависимой переменной, которая не объясняется моделью; модель ниже и выше прогнозов.<br>

<p><span class="blackbold">Исследовательская регрессия</span>, если ее использовать разумно, позволяет оценить объясняющую способность каждой переменной, а также сравнивать сочетания переменных путем перекрестного сравнения моделей, и выбора тех, которые лучше отражают  предположения о связи зависимой переменной с предикторами.</p>

<p>Приступим к моделированию. В общей сложности мы отобрали 11 независимых переменных, которые тестируются для моделирования зависимой переменной <b>Преступность</b>. Мы не определяем пока, какая из переменных будет окончательно включена в окончательную модель, вместо этого мы полагаемся на возможности  анализа данных, которые предлагает исследовательская регрессия.  
	
<p>Алгоритм <span class="blackbold">Exploratory Regression</span> <span class="red">ArcMAP10.x</span> отличается сложным интерфейсом и необходимостью заполнить несколько позиций диалогового окна: <span class="monospace">ArcToolbox >> Spatial Statistic Tools >> Modeling Spatial Relationships >> Exploratory Regression</span>.</p>

<div class="script">
<strong>Exploratory Regression</strong> <br>
Input Features: NYCTRACTs  <br>
Dependent Variable: Crime15y <br>
Candidate Exploratory Variables: poorsqrt, giniIndex, ... *11 независимых переменных заключаются <a href="#Таблица 6.1">(Таблица 6.1)</a><br> 
Weights Matrix File: Leave empty.  (*используется для вычисления пространственной автокорреляции остатков, если оставить это поле пустым, веса вычисляются на основе восьми ближайших соседей; эта весовая матрица не используется для расчета OLS) <br>
Output Report File: ... Exploratory.txt <br>
Output Results Table: Exploratory <br>
Maximum Number of Explanatory Variable: 8 (*модель будет строиться  максимум с четырьмя независимыми переменными) <br>
Minimum Number of Explanatory Variable: 1 <br>
Minimum Acceptable Adj R Squared: 0.75 <br>
Maximum Coefficient p value Cutoff: 0.05 <br>
Maximum VIF Cutoff: 7.5 <br>
Minimum Acceptable Jargue Bera p value: 0.05 <br>
Minimum Acceptable Spatial Autocorrelation p value: 0.05 <br>
OK
</div>

<p><span class="monospace">Исследовательская регрессия</span> выдает два файла - таблицу и отчет в <span class="monospace">TXT-формате</span>: <span class="monospace">Main Menu >> Geoprocessing >> Results >> Current Session >>
Exploratory Regression >> DC on Output Report File: Exploratory.txt.</span> Отчет состоит из нескольких разделов. </p>

<p><strong>Раздел 1: Краткое описание лучших моделей</strong> описывает три лучшие модели с самым высоким скорректированным <span class="monospace">R-квадратом</span> и обеспечивает следующую диагностику (см. <a href="#Таблица 6.2"></a>(Таблица 6.2).</p>
<br>

<a id="Таблица 6.2"></a> <span class="imgtitle">Таблица 6.2  Диагностические тесты, используемые в исследовательской регрессии</span>

<div class="table">
<table id="customers">
        <table border="1">

<tr>
	<th>Наименование диагностического теста</th>
<th>Что обнаруживает</th>
<th>Проверенная гипотеза (Когда значение p меньше уровня значимости, мы отвергаем нулевую гипотезу).</th>
</tr>

<tr>
	<td>AICc corrected Akaike Information Criterion|Скорректированный информационный критерий Акайке</td>
	<td>Общая мера соответствия и как мера для сравнения различных моделей</td>
	<td>Модель, у которой наименьшее значение, обеспечивает наилучшую пригодность среди протестированных</td>
</tr>

<tr>
<td>P–значение JB (Jarque-Bera)|<br>Тест Жарка–Бера </td>
<td>Нормальность остатков в качестве доказательства отсутствия смещенных остатков</td>
<td>Нулевая гипотеза: нормальное распределение остатков(ошибок) регрессии	<br>	
Альтернативная гипотеза: ненормальное распределение ошибок регрессии
</td>
</tr>

<tr>
<td>BreuschPagan test|<br>Тест Бреуша–Пагана </td>
<td>Проверка гетероскедастичности остаточных ошибок</td>
<td>Нулевая гипотеза: постоянная дисперсия ошибки остатков (гомоскедастичность)<br> 
Альтернативная гипотеза: непостоянная дисперсия ошибки регрессии (гетероскедастичность)
</td>
</tr>

<tr>
<td>Koenker’s studentized Breusch–Pagan K(BP)|<br>Статистика Кенкера (BP)</td>
<td>P-значение, как мера гетероскедастичности</td>
<td>Если ее значения меньше статистически значимых (p < 0,01), то смоделированные отношения не являются последовательными (либо из-за нестационарности, либо из-за гетероскедастичности)</td>
</tr>


<tr>
<td>Moran’s I|<br>Тест Морана I</td>
<td>Определение, являются ли ошибки остатков пространственно автокоррелированными</td>
<td>Нулевая гипотеза: нет пространственной автокорреляции в остаточных ошибках<br>
Альтернативная гипотеза: существует пространственная автокорреляция в остаточных ошибках
</td>
</tr>

<tr>
<td>VIF (variance inflation factor)|<br> Коэффициент инфляции дисперсии</td>
<td>Для оценки мультиколлинеарности </td>
<td>Указывается коэффициент инфляции с наибольшей дисперсией</td>
</tr>

<tr>
<td>SA -the p-value of the Global Moran’s I test|<br>P-значение глобального I-критерия Морана</td>
<td>Для обнаружения пространственной автокорреляции</td>
<td>Подтверждает либо опровергает нулевую гипотезу</td>
</tr>

</table>


<p>Модели (если таковые имеются), прошедшие все тесты, помечены как <span class="monospace">Passing Models|Проходящие модели</span>. Результаты сообщаются в соответствии с заданным значением "максимальное количество независимых переменных" (в данном случае мы указали <span class="greencursiv">11</span>) это означает, что <span class="blackbold">Исследовательская регрессия</span> проверит комбинации всех моделей, имеющих от одной независимой переменной до <span class="greencursiv">11</span>. Выходные данные включают три лучшие модели (вместе с пятью диагностиками) с одной независимой переменной, три лучшие модели с двумя независимыми переменными и так далее - до трех лучших моделей с одиннадцатью независимыми переменными. Кроме того, будут сообщены все проходящие модели. Если нет проходящих моделей, то последующие разделы раскрывают возможные причины, помогая определить, в каком направлении следует корректировать анализ.</p>
<br>

<a id="Explotory_11_1_раздел"><img src="Pict_1_6/Explotory_11_1_раздел.png" width="70%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.10 Фрагмент 1 раздела TXT-отчета исследовательской регрессии для 11 переменных

<p><b>1-й раздел TXT-Report: интерпретация результатов</b>. В этом разделе представлены три лучшие модели, которые имеют от одной до одиннадцати независимых переменных (мы установили это в качестве одного из наших параметров). <span class="monospace">Первая модель Choose 1 of 11 Summary</span> связывает изучаемую зависимую переменную - <b>Преступность</b> - с единственной выбранной переменной-предиктором, которая указана в верхней строчке столбца <span class="cursive">Model</span> - <b>Доля домохозяйств ниже уровня бедности</b>: только у этой переменной скорректированный <span class="monospace">R-квадрат</span> <span class="greencursiv">>0,80</span>. 
<span class="monospace">Вторая модель Choose 2 of 11 Summary</span> - с двумя переменными, здесь проверку прошли три варианта сочетания двух факторов:   
(1) <b>Доля домохозяйств ниже уровня бедности</b> и <b>Доля афроамериканского безработного населения</b>, (2) <b>Доля домохозяйств ниже уровня бедности</b> и <b>Среднегодовой доход домохозяйств</b>, также  (3) <b>Доля лиц со степенью бакалавра</b> и <b>Доля домохозяйств ниже уровня бедности</b>. <span class="monospace">Третья модель Choose 3 of 11 Summary</span>  предлагает три инварианта с тремя переменными (к уже перечисленным выше четырем факторам добавляются фактор <b>Средний возраст жителей</b> в разных сочетаниях).</p>

<p>Знаки перед переменными в столбце <span class="cursive">Model</span> <span class="greencursiv">"+"</span> означает положительную связь (<span class="greencursiv">+POORSQRT</span> означает, что с ростом доли домохозяйств, живущих ниже уровня бедности, возрастает число убийств в квартале), знак <span class="greencursiv">"-"</span> - отрицательную (<span class="greencursiv">-INCOME</span> указывает, что с ростом среднегодового дохода домохозяйств в квартале число убийств снижается).</p>

<p>Таким образом, каждая последующая модель "богаче" предыдущей на привлеченные для объяснения зависимой переменной признаки: в модели <span class="monospace">Choose 4 of 11 Summary</span> в трех инвариантах используется 6 признаков,  хотя в каждом конкретном варианте используется число переменных заявленных в выборе, т.е., в данном случае - 4. Следует обратить внимание на то, как растет показатель <span class="monospace">AdjR<sup>2</sup> </span> - скорректированный коэффициент детерминации (процент вариации, объясняемый моделью, равен квадрату коэффициента корреляции) с добавлением новых переменных на каждом следующем шаге: <b>Доля беднейших домохозяйств</b> (1 из 11, т.е., как единственный фактор) выдает <span class="monospace">AdjR<sup>2</sup> </span>равный <span class="greencursiv">0,82</span>; при задействовании в модели четырех факторов <span class="monospace">AdjR<sup>2</sup> </span> равен <span class="greencursiv">0,88</span>, т.е., коэффициент детерминации вырастает на <span class="greencursiv">0,04</span> и остается таковым (т.е., не оптимизируется - модель не объясняет больший процент выборки) на последующих шагах модели. Если скорректированный <span class="monospace">R-квадрат</span> уменьшается, то привлеченные переменные скорее всего оказались бесполезны для модели.</p>

<p>Посмотрим на комбинаторику <span class="monospace">Choose 6 of 11 Summary</span></p>

<a id="Explotory_11_1_раздел"><img src="Pict_1_6/Explotory_11_1_раздел_6_перемн.png" width="80%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.11 Скриншот фрагмента 1 раздела TXT-отчета исследовательской регрессии  - таблица для 6 переменных

<p>Каждая из трех моделей <a href="#Explotory_11_1_раздел">(Рис. 6.11)</a> для шести переменных немного отличается от двух других как набором факторов, так и их очередностью. Все три модели проходят (как и предыдущие - для меньшего числа переменных) имеют высокий <span class="monospace">Adjusted R-squared Results|Cкорректированный коэффициент детерминации AdjR<sup>2</sup></span>. Обратимся к другим индикаторам <span class="monospace">Отчета</span>.</p>

<p><span class="monospace">AICc corrected Akaike Information Criterion|Cкорректированный информационный критерий Акайке</span>: легко заметить, что в вариантах моделей для любого количества переменных на первое место выведена модель с наименьшим критерием Акайке.</p>

<p>Следующий тест <span class="monospace">P–значение JB (Jarque-Bera)|P-значение Жарка-Бера</span> или <span class="monospace">Критерий нормальности остатков</span>, во всех наших тестах: <span class="greencursiv">0,00</span> при установленном минимальном значении <span class="greencursiv">0,05</span> и это значит, что модели не прошли проверку по этому критерию.</p>

<p><span class="monospace">P-value Koenker’s studentized Breusch–Pagan K(BP)|P-значение Кенкера Брейша–Пагана</span> - мера гетероскедастичности. <strong>Гетероскедастичность </strong> — <span class="bolditalic">понятие, означающее неоднородность наблюдений, выражающуюся в неодинаковой дисперсии случайной ошибки регрессионной модели</span>. Когда <span class="monospace">статистика Кенкера (BP)</span> статистически значима, существует гетероскедастичность и взаимосвязи модели ненадежны. В этом случае вместо <span class="monospace">P-значения t-статистики</span> следует использовать  <span class="monospace">t-статистику</span> и <span class="monospace">Robust probabilities|Надежные вероятности</span>, которые могут быть интерпретированы как <span class="monospace">P-значения</span>, при этом значения  меньше <span class="greencursiv">0,01</span>, являются статистически значимыми <a href="BIBLIO.html#Grekousis_2020">[Grekousis, 2020, p. 386]</a>.</p>

<p><span class="monospace">VIF variance inflation factor|Коэффициент инфляции дисперсии</span> используется для оценки <strong>мультиколлинеарности</strong> (потенциальной взаимосвязи объясняющих факторов-переменных); в вышеупомянутых моделях мультиколлинеарность не является проблемой, так как <span class="monospace">VIF</span> во всех случаях меньше <span class="greencursiv">4</span>.</p>

<p><span class="monospace">SA P-value of the Global Moran’s I test|P-значение глобального I-критерия Морана</span> для обнаружения пространственной автокорреляции привлеченных переменных; в нашем случае <span class="greencursiv">0,00</span>.</p>

<p><b>2-й раздел TXT-Report</b> - <span class="monospace">Exploratory Regression Global Summary|Общее резюме Исследовательской Регрессии</span>. В этом разделе перечислены пять диагностик и процент моделей, прошедших каждый из этих тестов (<span class="monospace">Percentage of Search Criteria Passed</span>). В случае, если ни одна модель не проходит, этот раздел помогает в выявлении потенциальных причин, по которым модели не работают должным образом. Например, <span class="bolditalic">если тест на нормальность не является статистически значимым для большинства моделей, то следует поставить под сомнение нормальность распределения как зависимой, так и независимых переменных</span>. Кроме того, мы можем столкнуться с пространственно автокоррелированными остатками, которые указывают на отсутствующую (критически важную) переменную. Довольно часто эта пропущенная переменная является <b>географической переменной</b>, такой как расстояние от ориентира (например, расстояние от центра города), и тогда выход заключается в использовании <span class="blackbold">Географически Взвешенной Регрессии</span>.</p>

<a id="Explotory_11_2_раздел"><img src="Pict_1_6/Explotory_11_2_раздел.png" width="55%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.12 Скриншот Раздела 2 TXT-отчета исследовательской регрессии Exploratory Regression Global Summary

<p>В рассматриваемых результатах регрессионного анализа обнаруживаются две серьезные проблемы: ни одна из <span class="greencursiv">2035</span> моделей, построенных алгоритмом, не прошла тест на нормальность ошибок <span class="monospace">Jarque–Bera</span> (минимальное значение <span class="greencursiv">0,10</span>), и тест на отсутствие пространственной автокорреляции (нулевая гипотеза <span class="monospace">Глобального индекса Морана</span>).</p>

<p><b>3-й раздел TXT-Report</b>: <span class="monospace">Summary of Variable Significance|Краткое описание значимости переменных</span>. В этом разделе для каждая независимой объясняющей переменной (предиктора) указана ее значимость (определяемая коэффициентом детерминации) и характер связи с зависимой переменной:</p>

1) % Significant|Процент (относительно числа всех протестированных) моделей, в которых переменная является статистически значимой (в соответствии с коэффициентом детерминации AdjR<sup>2</sup>);<br> 
2) % Negative|Процент моделей, в которых связь предиктора с зависимой переменной является отрицательной;<br>
3) % Positive|Процент моделей, в которых связь предиктора с зависимой переменной является положительной. 

<p><span class="bolditalic">Переменные с высоким процентом значимости являются сильными предикторами и, как правило, имеют  один и тот же (положительный или отрицательный) знак связи с зависимой переменной. Переменные с небольшим процентом значимости, и зачастую "грешащие" непостоянством знака связи, перегружают модель и являются кандидатами на удаление</span>.</p>

<a id="Explotory_11_3_раздел"><img src="Pict_1_6/Explotory_11_3_раздел.png" width="55%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.13 Скриншот Раздела 3 TXT-отчета Summary of Variable Significance исследовательской регрессии

<p>В нашей модели две независимые переменные неизменно значимы и положительны в 100% моделей и могут считаться сильными предикторами феномена тяжких преступлений против личности: <span class="monospace">Доля хозяйств ниже уровня бедности</span>, и <span class="monospace">Доля афроамериканского безработного населения</span>. Сильные позиции и у пяти следующих переменных с устойчивым знаком связи:<br>
<span class="monospace">Средний возраст населения MEDIANAGE</span> (негативная связь - чем ниже возраст - тем больше совершается убийств);<br>
<span class="monospace">Объемный след квартала FPRNTLOG</span> (положительная связь - чем выше и плотнее здания в квартале - тем выше преступность);<br>
<span class="monospace">Среднегодовой доход домохозяйств INCOME1000</span> (негативная связь - чем выше доход - тем ниже преступность);<br>
<span class="monospace">Индекс Джини GINI_LG</span> (положительная связь - чем выше значение индекса и более неравно распределены доходы - тем  выше число убийств);
<span class="monospace">Доля лиц с бакалаврской степенью BACHPRCNT</span> (отрицательная связь).<br> 

<p>Два последних признака - <span class="monospace">Общий уровень безработицы UNEMP_RATE</span> и <span class="monospace">Число онкологических заболеваний CANCRSQRT</span> не имеют постоянного знака и, как таковые, не являются надежными предикторами.</p>

<p><b>4-й раздел TXT-Report</b> <span class="monospace">Summary of Multicollinearity|Краткое описание мультиколлинеарности</span> <span class="bolditalic">сообщает, сколько раз две или более переменных с высокой мультиколлинеарностью включались в модель, обеспечивая тем самым одинаковый процент вариации. Оставляя только одну из таких переменных (как правило - с большим коэффициентом детерминации), мы избежим мультиколлинеарности и построим лучшую модель</span>.</p>

<a id="Explotory_11_4_раздел"><img src="Pict_1_6/Explotory_11_4_раздел.png" width="40%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.14 Скриншот Раздела 4 TXT-отчета Summary of Multicollinearity Исследовательской регрессии 

<p>В нашей модели мультиколлинеарность не зафиксирована ни для одной из пар признаков - что свидетельствует о корректном выборе переменных по результатам проведенного ранее <span class="blackbold">Анализа Главных Компонент</span>.</p>

<p><b>5-й раздел TXT-Report</b> представляет два теста: <span class="monospace">Summary of Residual Normality (JB)|Краткое описание диагностики Нормальности Ошибок</span> и <span class="monospace">Summary of Residual Spatial Autocorrelation (SA)|Краткое описание Пространственной Автокорреляциии</span>. В разделе приведены три модели, не обязательно прошедшие всю диагностику (<span class="monospace">passed models</span>), но обладающие  самыми высокими <span class="monospace">P–значениями Жака-Берра (нормальность ошибок)</span> и три модели с самыми высокими <span class="monospace">P-значениями Морана I (пространственная автокорреляция)</span>. Этот раздел особенно полезен, если ни одна модель не проходит тесты. Проверяя <span class="monospace">P-значения теста Жарка–Берры</span> и <span class="monospace">теста Морана I</span>, мы оцениваем, <span class="bolditalic">насколько далека модель от выполнения предположений о наличии нормально распределенных остатков и нестационарных автокоррелированных остатков</span>.</p>

<p>Вторым продуктом работы алгоритма <span class="blackbold">Исследовательской регрессии</span> является <span class="monospace">Exploratory Table</span> (<span class="monospace">Results >> Exploratory Regression >> Output ResultTable</span>), в которой суммируются все модели, преодолевающие пороговое значение Скорректированного коэффициента детерминации <span class="monospace">AdjR<sup>2</sup></span>, "отсекающее"  значения <span class="monospace">VIF (Max VIF Value)</span> и <span class="monospace">Cкорректированного информационного критерия Акайке (AICc)</span>.  Каждая строка в таблице описывает модель, которая соответствует этим критериям, независимо от того, проходит ли она тесты в целом. Эта таблица полезна, в случаях, подобный рассматриваемому, когда мы рассматриваем возможность использования модели, хотя одно или несколько допущений не выполняются. Например, наиболее распространенным нарушенным предположением является нормальность ошибок. В таких случаях мы можем отсортировать таблицу по значениям <span class="monospace">AICc</span> и использовать модель с минимальным значением <span class="monospace">критерия Акайке</span>, которая при этом имеет лучшие показатели по другим диагностикам - прежде всего <span class="monospace">коэффициенту детерминации AdjR</span> <a href="#Explotory_11_table_vuvod1">(Рис. 6.15)</a>.</p>

<a id="Explotory_11_table_vuvod1"><img src="Pict_1_6/Explotory_11_table_vuvod1.png" width="80%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.15 Скриншот экспортированной в Excel выводной таблицы Исследовательской Регрессии: значения отсортированы по минимальным значениям AICc и максимального скорректированного R-квадрат (коэффициент детерминации)

<p>Лучшей моделью линейной регрессии для зависимой переменной с учетом всех изложенных обстоятельств, является модель с семью независимыми переменными, к числу которых относятся (в скобках указан знак связи):
<ol>
<li>Доля домохозяйств ниже уровня бедности (+)</li>
<li>Доля афроамериканского безработного населения (+)</li>
<li>Средний возраст населения (-)</li>
<li>Объемный след застройки (+)</li>
<li>Среднегодовой доход домохозяйств (-)</li>
<li>Индекс Джини (+)</li>
<li>Доля лиц со степенью бакалавра (-)</li>
</ol>

<p>Заключая раздел, посвященный возможностям простой линейной регрессии, мы должны вновь вспомнить на каких предположениях о характере связи между зависимой переменной и предикторами она основывается.</p>

<ul>
<li>Связь между <strong>Y</strong> и <strong>X</strong> линейна при любом количестве привлеченных объясняющих факторов;</li>
<li>Предикторы независимы, т.е., между ними отсутствует автокорреляция, а остатки независимы друг от друга;</li>
<li>Распределение зависимой переменной и предикторов нормально;</li>
<li>Гомоскедастичность, т.е., дисперсия остатков не изменяется (увеличивается или уменьшается) с соответствующими значениями зависимой переменной.</li>
</ul>

<p>В модели преступности Нью-Йорка под сомнение должны быть поставлены пункт 1, т.е., <span class="bolditalic">связь между преступностью и всеми привлеченными факторами, скорее всего не имеет простого линейного характера</span>. Мы могли убедиться на парных точечных графиках, построенных в программе <span class="blue">SAGA GIS</span>, что при снижении <b>Доходов домохозяйств</b> <b>Преступность</b> действительно растет, но только до определенного предела, после которого достигается небольшое плато, а при дальнейшем росте бедности - падает; иными словами, очень бедные люди в той же мере не склонны к совершению тяжких преступлений, как и весьма обеспеченные. К сожалению, наши данные не соответствуют в должной степени и пункту 3 (<b>нормальность распределения</b>). В итоге полученная нами модель хоть и представляет интерес с точки зрения исследования самого феномена, но не может считаться ни законченной, ни исчерпывающей.</p>
<br>

			<h3 id="h3_4">6.4. OLS - Метод наименьших квадратов</h3>


<p><span class="blackbold">Ordinary Least Squares (OLS)|Метод наименьших квадратов (МНК)</span> - <span class="bolditalic">это статистический метод оценки неизвестных параметров (коэффициентов) модели в уже рассмотренном нами уравнении линейной регрессии</span>. <span class="blackbold">Регрессия OLS</span> <span class="bolditalic">определяет эти значения путем минимизации суммы квадратов вертикальных расстояний от наблюдаемых точек до  прямой линии регрессии (сумма квадратов остатков)</span> и также называется <span class="blackbold">Линейной регрессией OLS</span> или просто <span class="blackbold">Линейной регрессией</span>.</p>

<p>Запустим <span class="blackbold">OLS</span> для семи переменных, преодолевших барьер</span> <span class="monospace">Summary of Variable Significance</span> <span class="greencursiv">90%</span>, выбранных с помощью <span class="monospace">Исследовательского регрессионного анализа</span>:
<ol>
<li>Доля домохозяйств ниже уровня бедности,</li>
<li>Доля афроамериканского безработного населения,</li>
<li>Средний возраст населения,</li>
<li>Объемный след застройки,</li>
<li>Среднегодовой доход домохозяйств,</li>
<li>Индекс Джини,</li>
<li>Доля лиц со степенью бакалавра.</li>
</ol>

<span class="boldcurshad">ArcToolbox >> Spatial Statistic Tools >> Modeling Spatial Relationships >> Ordinary Least Squares</span><br>

<div class="script">
<strong>Ordinary Least Squares</strong><br>
Input Feature Class: NYCTRACTs (*файл кварталов Нью-Йорка с необходимыми полями зависимой переменной и предикторов)<br> 
Unique ID Field: ID<br>
Output Feature Class: ... OLS_7values.shp<br>
Dependent Variable: Murdr15y (*изучаемая зависимая переенная)<br>
Explanatory Variable: poorsqrt, afrunmploysrt, medianage ....income (*набор объясняющих независимых переменных-предикторов<br>
Output Report File: ... OLS7values.pdf<br>
Additional Options: <br>
Coefficient Output Table: ... OLS7valCoefficient<br>
Diagnostic Output Table: ... OLS7valDiagnostics<br>
Output Report File: OLS7values.pdf<br>
OK
</div> 

<p>Отчет алгоритма доступен как обычно во вкладке результаты: <span class="monospace">Main Menu >> Geoprocessing >> Results >> Current Session >> Ordinary Least Squares >> RC on Output Report File: OLS7values.pdf.</span></p>

<p><strong>1-й раздел отчета</strong>  <span class="monospace">Summary of OLS Results - Model Variables</span> - представляет таблицу значений индексов, которые уже знакомы нам по алгоритму <span class="blackbold">Explanatory Regression</span> для использованных переменных (предикторов) модели.</p>

<a id="OLS Results"><img src="Pict_1_6/OLS Results.png" width="80%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.16 Скриншот Раздела 1 Summary of OLS Results - Model Variables и 2 Summary of OLS Diagnostics PDF-отчета Метода наименьших Квадратов (таблица экспортирована в Excel)

<p>Интерпретация первого раздела тесно связана со вторым разделом (что объясняет сплошную индексацию буквами английского алфавита: <strong>[a]</strong> в <span class="monospace">Summary of OLS Results - Model Variables</span> и <strong>[d]</strong> во второй части раздела <span class="monospace">OLS Diagnostics</span>. При интерпретации необходимо учитывать следующие позиции, изложенные в PDF-отчете инструмента под таблицей <span class="monospace">OLS-Диагностики (Notes on Interpretation)</span> <a href="BIBLIO.html#Grekousis _2020">[Grekousis, 2020]</a>:</p>

<span class="script">

[a] Коэффициенты (это и есть те самые β-бета множители перед переменными в формуле линейной регрессии): представляют силу и тип взаимосвязи между каждой объясняющей переменной и зависимой переменной. Звездочка рядом с цифрой указывает на статистически значимое значение P (P <span class="greencursiv">< 0,01</span>).<br> 
[b] Вероятность и надежная вероятность (robust_Pr): звездочка (*) указывает, что коэффициент статистически значим (P <span class="greencursiv">< 0,01</span>); если статистика Кенкера (BP) [f] статистически значима, используем столбец Надежной вероятности (robust_Pr) для определения значимости коэффициента.<br>
[c] Коэффициент инфляции дисперсии (VIF): значения Коэффициента инфляции большой дисперсии (VIF) (<span class="greencursiv">> 7,5</span>) указывают на избыточность среди объясняющих переменных. <br>
[d] Коэффициент детерминации R-Квадрат, Скорректированный Коэффициент детерминации AdjR<sub>2</sub>  и Информационный критерий Акайке (AICC): показатели производительности и соответствия модели.<br>
[e] Совместная статистика F и Вальда: звездочка (*) указывает на общую значимость модели (P <span class="greencursiv">< 0,01</span>);  если статистика Кенкера (BP)  [f] статистически значима, используйте статистику Вальда для определения общей значимости модели. <br> 
[f] Статистика Кенкера (BP): когда этот тест статистически значим (P<span class="greencursiv">< 0,01</span>), моделируемые взаимосвязи не являются согласованными (либо из-за нестационарности, либо гетероскедастичности). Следует полагаться на надежные вероятности (robust_Pr) для определения значимости коэффициента и на статистику Вальда для определения общей значимости модели. Когда тест Кенкера статистически значим, это означает, что одна или несколько объясняющих переменных распространены закономерно в географическом пространстве и, следовательно, модель может быть улучшена с использованием географически взвешенной регрессии. <br>
[g] Статистика Жарка-Бера: когда этот тест статистически значим (P <span class="greencursiv">< 0,01</span>), предсказания модели смещены (остатки распределены ненормально).<br>
</span>

<p>Краткие указания, изложенные в этом списке обычно составляют содержание интерпретации результатов регрессионной модели в руководствах по <span class="red">ArcMAP10.x</span> <a href="BIBLIO.html#Bajjali_2018">[Bajjali, 2018</a>; <a href="BIBLIO.html#Pimpler_2017">Pimpler, 2017]</a>. Вообще говоря, уже первая колонка таблицы <span class="monospace">Summary of OLS Results - Model Variables</span> (первый раздел PDF-отчета) представляет нам искомые бета-коэффициенты для переменных уравнения регрессии (<strong>Y</strong> по <strong>X</strong>), однако, прежде чем их использовать необходимо разобраться в результатах детально  и заглянуть чуть глубже в результаты отчета.</p>

<p><span class="monospace">Number of Observations|Число Наблюдений</span> в <span class="monospace">OLS Diagnostics</span> как легко догадаться означают просто общее количество объектов в модели - в данном случае общее число кварталов Нью-Йорка, обеспеченных значениями соответствующих  переменных.</p>

<p><span class="monospace">Multiple R-Squared [d]|Множественный R-квадрат</span> является уже знакомым нам коэффициентом детерминации - мера объясненной вариации или величины вариации переменной <strong>Y</strong>, которую можно смоделировать с помощью линейной зависимости от <strong>X</strong>. 

<p><span class="monospace">Сумма квадратов регрессии</span>, также называемая <span class="monospace">Объясненной вариацией</span> (модели) рассчитывается как:</p>

<a id="SummRegressSQ"><img src="Pict_1_6/SummRegressSQ.png" width="20%" height="relative"></a>

<p>Это мера <span class="monospace">Объясненной вариации</span> или величины вариации <strong>Y</strong>, которую можно смоделировать с помощью линейной зависимости от <strong>X</strong>.</p>

<p><span class="monospace">Сумма квадратов ошибок</span>, также называемая <span class="monospace">Необъяснимой вариацией</span> или остаточной суммой квадратов:</p>

<a id="SummErrSq"><img src="Pict_1_6/SummErrSq.png" width="20%" height="relative"></a>

<p>Тогда <span class="monospace">Общая вариация</span> <strong>Y</strong> может быть рассчитана как:</p><br>

Общая вариация = Объясненная вариация регрессией + Необъясненная вариация, или:<br>

SST: SSR + SSE

<p><span class="monospace">Коэффициент детерминации</span>, обозначаемый как <span class="monospace">R<sup>2</sup> (R-квадрат)</span>, представляет собой процент вариации, объясняемой моделью. Он рассчитывается как отношение между изменением прогнозируемых значений зависимой переменной (<span class="monospace">Объясненная вариация SSR</span>) к изменению наблюдаемых значений зависимой переменной. Он равен квадрату коэффициента корреляции.</p>

R<sup>2</sup>= SSR/SST  

<p>Проще говоря, это частное от деления квадрата суммы разницы прогнозируемых значений <strong>Y</strong><sub>i</sub>  со средним значением наблюдаемых <strong>Y</strong> (квадрат суммы регрессии),  на квадрат суммы разницы наблюдаемых значений <strong>Y</strong><sub>i</sub> со средним значением наблюдаемых <strong>Y</strong>.</p>

<p>Коэффициент детерминации рассчитывается по формуле:</p> 

R <sup>2</sup>= 1 - (SSE/SST)

<p>Поскольку остаточная сумма квадратов минимизируется в обычной регрессии наименьших квадратов, отношение <span class="monospace">SSE/SST</span> всегда меньше <span class="greencursiv">1</span>. Чем меньше  <span class="monospace">Необъясненная вариация SSE</span>, тем меньше соотношение в уравнении и тем больше <span class="monospace">Коэффициент детерминации</span>, и, следовательно, <span class="monospace">Объясненная вариация</span>. Чем больше значение коэффициента, тем надежнее модель.  Нулевое значение указывает на то, что изменение зависимой переменной не объясняется и, скорее всего, модель не может быть использована, в то время как значение <span class="greencursiv">1</span> объясняет всю изменчивость данных, идеально вписывающуюся в линию на точках данных. Например, если <span class="monospace">R-квадрат </span>равен <span class="greencursiv">82%</span>, это обычно означает, что <span class="greencursiv">82%</span> вариации <b>Y</b> обусловлено изменениями значений <b>X</b>, что означает, что <b>X</b> является хорошим предиктором для <b>Y</b>, имеющим вероятностную линейную зависимость <a href="BIBLIO.html#Pimpler_2017">[Pimpler, 2017]</a>.</p>	

<p>Так как модель линейной регрессии соответствует линии для минимизации так называемых <span class="monospace">Остатков (Residuals)</span>, идеальное соответствие приведет к нулевым остаткам. Когда остатки невелики, у нас есть хорошая подгонка линии. По мере увеличения остатков модель становится менее надежной; она выдает прогнозируемые значения, которые сильно отклоняются от наблюдаемых.</p>

<p>В общем случае, когда переменные не коррелируют, ожидается, что каждая из них будет объяснять различную величину вариации зависимой переменной. Тем не менее, переменные редко бывают некоррелированными: условно - в рамках конкретной модели -  привлеченные к объяснению переменные считаются "независимыми", но по большому счету мы никогда не знаем этого наверняка. Г. Грекоузис <a href="BIBLIO.html#Grekousis_2020">[Grekousis, 2020]</a> предлагает наглядное графическое объяснение <span class="monospace">Коэффициента Детерминации R-квадрат</span>.</p>

<a id="VariationExplained"><img src="Pict_1_6/VariationExplained.png" width="65%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.17 Графическая репрезентация феномена изменчивости зависимой переменной от нескольких предикторов, источник <a href="BIBLIO.html#Grekousis_2020">[Grekousis, 2020]</a><br>

<p>Рисунок <a href="#VariationExplained">(Рис. 6.17)</a> хорошо объясняет различную роль нескольких предикторов в объяснении зависимой переменной <strong>Y</strong>.  В случаях (A) простой линейной регрессии переменная <strong>X<sub>1</sub></strong> объясняет часть <strong>a</strong>  вариации независимой переменной <strong>Y</strong> с помощью простой линейной регрессии.  В множественной линейной регрессии (B) включение второй переменной <strong>X<sub>2</sub></strong> приводит к дополнительному объяснению <strong>b</strong> части вариации, причем той, которую не объясняла переменная <strong>X<sub>1</sub></strong>. Общая объясненная вариация <strong>R<sup>2</sup></strong>  равна <strong>a + b</strong>. В ситуации (C) при том  же числе предикторов (2) существует перекрывающаяся часть <strong>c</strong>  вариации <strong>Y</strong>, которая объясняется обеими независимыми переменными, поэтому ее следует включать только один раз в общую объясненную вариацию. Иными словами в модель должна быть включена только неперекрывающаяся часть вариации, объясненной через <strong>X<sub>2</sub></strong>, а именно <strong>"b - c"</strong>, и тогда общий объем объясненной <strong>R<sub>2</sub></strong> равен <strong>a +(b - c)</strong>.  В ситуации (D) <strong>X<sub>1</sub></strong> и <strong>X<sub>2</sub></strong> сильно коррелируют и объясняют почти одинаковую долю вариации,  дополнительная вариация, объясненная при включении <strong>X<sub>2</sub></strong> в модель, является частью <strong>d</strong>. Конечный объем объясненной вариации<strong>R<sub>2</sub></strong> равен <strong>"a + d"</strong>, где <strong>a</strong> - изменение, объясняемое <strong>X<sub>1</sub></strong>, а <strong>d</strong> - не перекрывающееся изменение между <strong>X<sub>1</sub></strong> и <strong>X<sub>2</sub></strong>. Если <strong>X<sub>1</sub></strong> объясняет <span class="greencursiv">80%</span> вариации, то при добавлении <strong>X<sub>2</sub></strong> объясненная вариация увеличивается до <span class="greencursiv">82%</span>. Обычно </strong>это означает, что <strong>X<sub>2</sub></strong> помогает объяснить дополнительные <span class="greencursiv">2%</span> объясненной вариации, а не то, что <strong>X<sub>2</sub></strong> объяснил бы <span class="greencursiv">2%</span>, если бы <strong>X<sub>1</sub></strong> если бы был включен в качестве единственного фактора в другую модель. </p>
 
<p>Небольшой <span class="monospace">Коэффициент Детерминации</span> не обязательно является признаком недостаточной регрессионной модели. То, как мы интерпретируем <span class="monospace">R-квадрат</span>, зависит от масштабов исследования и исследовательских вопросов. Следует иметь ввиду, что для определения взаимосвязей между зависимыми и независимыми переменными  может быть полезен даже низкий <span class="monospace">R-квадрат</span>, поскольку и такая, модель все еще может иметь статистически значимые независимые переменные (низкие <span class="monospace">P-значения</span>).  Другими словами, <span class="bolditalic"> при низком процентном значении Объясненной вариации взаимосвязи могут все еще существовать, и как таковая модель будет полезна для выявления тенденций</span>. По этой причине <span class="monospace">R<sup>2</sup></span>всегда следует оценивать с использованием графика остатков <a href="BIBLIO.html#Grekousis_Gialis_2018">[Grekousis, Gialis, 2018]</a>.</p> 

<p>В нашей модели <span class="monospace">R<sup>2</sup></span> равен <span class="greencursiv">0,876</span>, что  казалось бы означает что модель объясняет почти <span class="greencursiv">88%</span> вариации зависимой переменной. Однако  <span class="monospace">R-квадрат</span> не дает представления о том, насколько статистически значима гипотетическая взаимосвязь. Для этого  используется <span class="monospace">F-критерий</span> общей значимости</p></p>

<p>Еще одна близкая  по функции оценка <span class="monospace">Adjusted R-Squared|Скорректированный R-Квадрат</span> — это  <span class="monospace">Коэффициент детерминации</span>, скорректированный на количество переменных, так как каждая добавленная переменная увеличивает объясненную вариацию зависимой переменной. Как <span class="monospace">R-квадрат</span>, так и <span class="monospace">Скорректированный R-квадрат</span>, используются для оценки процента общего объясненного отклонения. Тем не менее, между ними есть существенная разница. В то время как <span class="monospace">R-квадрат</span> предполагает, что каждая отдельная переменная объясняет изменение Y, <span class="monospace">скорректированный R-квадрат</span> объясняет процент вариации только тех независимых переменных, которые влияют на <strong>Y</strong>.  <span class="monospace">R-квадрат</span> имеет тенденцию увеличиваться с каждой дополнительной переменной, что приводит нас к неправильному выводу о том, что мы создаем лучшую модель. Фактически, добавляя все больше и больше переменных, мы сталкиваемся с проблемой избыточности данных и перегрузки модели. Использование <span class="monospace">Скорректированного AdjR<sup>2</sup></span>, позволяет определить, какие переменные полезны, а какие нет, и рассмотреть возможность сохранения только тех переменных, которые увеличивают именно <span class="monospace">Скорректированный R-квадрат</span>. Для сравнения исследователь всегда может добавить новую переменную и запустить <span class="blackbold">OLS</span> с расширенным набором переменных: например, в данной модели добавление переменной <b>Общий уровень безработицы</b> увеличивает R<sup>2</sup> только на <span class="greencursiv">0,012</span>. Тем не менее, согласно <span class="monospace">Adjusted R-Squared</span> [d]: наш набор из семи переменных объясняет <span class="greencursiv">87,5%</span> тяжких преступлений в Нью-Йорке.</p>

<p>В отчете <span class="blackbold">OLS</span> приводится также величина <span class="monospace">Standard Error (Deviation) of Regression|Стандартная ошибка оценки</span>, представляющая собой квадратный корень из суммы квадратов ошибок, разделенной на степени свободы:</p>

<a id="Standart_Error"><img src="Pict_1_6/Standart_Error.png" width="20%" height="relative"></a>
<br>

<p>Показатель <span class="monospace">Стандартная ошибка</span> демонстрирует насколько близко или далеко в среднем находятся наблюдения от линии наименьших квадратов. Примерно <span class="greencursiv">95%</span> наблюдений должны находиться в пределах двух стандартных ошибок от линии регрессии</a>. В этом отношении мы можем использовать стандартное отклонение регрессии в качестве приблизительной оценки 95% интервала прогнозирования. <span class="monospace">Стандартная ошибка регрессии</span> имеет те же единицы измерения, что и зависимая переменная. Предпочтительны более низкие значения стандартных ошибок, указывающие на меньшие расстояния между точками данных и подобранными значениями. Комбинируя <span class="monospace">R-квадрат</span> и <span class="monospace">Стандартную ошибку регрессии</span>, мы можем лучше оценить достоверность нашей модели. В некоторых случаях невысокое значение <span class="monospace">R<sup>2</sup></span>может компенсироваться низкими значениями <span class="monospace">StdError</span>. Так в нашей модели значение <span class="monospace">Стандартной ошибки</span> оказались большим только для одной переменной <span class="monospace">Индекса Неравенства Доходов Джини</span> (<span class="greencursiv">0,492621</span>  при минимальном значении <span class="greencursiv">0,0</span> и максимальном - <span class="greencursiv">1</span>.</p>

<p><span class="monospace">F-Test of the Overall Significance|F-Критерий общей значимости</span>. Статистика F-критерия общей значимости модели, оценивает, являются ли коэффициенты регрессии Метода Наименьших Квадратов статистически значимыми</a>.</p>

<a id="F-Test_Overall Significance"><img src="Pict_1_6/F-Test_Overall Significance.png" width="20%" height="relative"></a><br>

где SSR — это  мера объясненной вариации из квадратичной регрессии,<br>
SSE - необъясненная вариации или сумма квадратов ошибок,<br> 
DFM: p - 1  степень свободы для модели, где p - количество параметров модели,<br>
DFE: n - p  это степени свободы для ошибки, где n - количество наблюдений.

<p>В контексте регрессионного анализа большие или низкие значения <span class="monospace">F-статистики</span> не указывают на какую-либо значимость модели; содержательные выводы могут быть сделаны только при сравнении конкретных значений с  пороговыми <span class="monospace">P-значениями</span>. Если <span class="monospace">F-статистика</span> мала (например, менее <span class="greencursiv">0,05</span>), то мы можем отвергнуть нулевую гипотезу и принять, что регрессионная модель статистически значима. В этом случае мы утверждаем, что наблюдаемая тенденция не обусловлена случайной выборкой из множества наблюдений. Если значение <span class="monospace">F-статистики</span> велико (например, больше <span class="greencursiv">0,05</span>), то мы не можем отвергнуть нулевую гипотезу. В этом случае мы должны быть осторожны в том, как интерпретировать результаты, поскольку невозможно определенно утверждать, что между <strong>Y</strong> и <strong>X</strong> отсутствует зависимость. В этом случае остаются вероятными три гипотезы <a href="BIBLIO.html#Grekousis_Gialis_2018">[Grekousis, Gialis, 2018]</a>:</p>

<ol>
<li>Между <strong>X</strong> и <strong>Y</strong> нет линейной зависимости. Тем не менее, может существовать нелинейная зависимость, например, экспоненциальная или логарифмическая. </li>
<li>Переменная <strong>X</strong> может объяснить небольшую часть вариации <strong>Y</strong>, но этого недостаточно, чтобы считать модель статистически значимой, используя только <strong>X</strong>. Возможно, нам потребуется добавить еще несколько переменных, чтобы объяснить <strong>Y</strong>.</li>
<li>Линейная зависимость все же существует, но размер нашей выборки слишком мал, чтобы ее можно было обнаружить</li>
</ol>

<p>В нашей модели <span class="monospace">F-критерий</span> общей значимости характеризуется в разделе <span class="monospace">OLS Diagnostics</span> <a href="#OLS Results">(Рис. 6. 16)</a> тремя показателями: <span class="monospace">Joint F-Statistic</span> <span class="greencursiv">2114,109</span> (само по себе ни о чем не говорящее значение); <span class="monospace">Prob (>F)</span> <span class="greencursiv">7,2100 </span> degrees of freedom (число степеней свободы); <span class="monospace">Статистическая значимость</span>  <span class="greencursiv">0,000000</span> т.е., менее <span class="greencursiv">0,05</span>. Таким образом, мы можем отвергнуть нулевую гипотезу и принять, что регрессионная модель статистически значима</p>

<p><span class="monospace">t-Statistic (Coefficients’ Test)|t-статистика или Тест Коэффициентов</span>. <span class="monospace">t-статистика</span> в регрессионном анализе — это  статистика, используемая для проверки того, является ли коэффициент <span class="monospace">b</span> уравнения линейной регрессии статистически значимым - для решения вопроса о том, какие независимые переменные оставить в модели, а какие - исключить..</p>

 t = b / SE<sub>b</sub><br> 
 где SE<sub>b</sub> - стандартная ошибка расчетного коэффициента b

<p>Однако, прежде чем мы оценивать <span class="monospace">t-статистику</span>, необходимо проверить <span class="monospace">статистику Кенкера (BP)</span> <a href="BIBLIO.html#Koenker_Hallock_2001">[Koenker, Hallock, 2001]</a>. Если <span class="monospace">статистика Кенкера (BP)</span> статистически значима, то делается вывод о существовании гетероскедастичности, и взаимосвязи модели  признаются ненадежными. В этом случае вместо <span class="monospace">P-значения t-статистики</span> следует использовать  <span class="monospace">Robust t-statistic|Робастную статистику</span> и <span class="monospace">Robust probabilities|Надежные вероятности</span> (рассчитываемые автоматически). Робастные (заслуживающие доверия, надежные) вероятности   могут быть интерпретированы как <span class="monospace">P-значения</span>, при этом значения, например, меньше <span class="greencursiv">0,01</span> являются статистически значимыми. </p>

<p>Для небольшого <span class="monospace">P-значения t-статистики</span> мы отвергаем нулевую гипотезу о том, что коэффициент <span class="monospace">b</span> равен нулю, и принимаем его значение как статистически значимое. В этом случае независимая переменная <strong>X</strong>, которой присваивается коэффициент, важна для расчета зависимого <strong>Y</strong>. Для большого <span class="monospace">P-значения</span> мы не можем принять <span class="monospace">b</span>  как статистически значимое, и нам следует рассмотреть возможность удаления соответствующей независимой переменной из модели.</p>

<p><strong>Во втором разделе PDF-отчета </strong> <span class="monospace">OLS Diagnostics</span> <a href="#LS Results">(Рис. 6. 16)</a>  предпоследнюю строчку занимает <span class="monospace">Статистика Кенкера</span>. В нашей модели <span class="monospace">Koenker (BP) Statistic [f]</span> равна <span class="greencursiv">769,479969</span> при <span class="monospace">Prob(>chi-squared)</span> <span class="greencursiv">0,000000*</span> и семи степенях свободы  (т.е., статистическая значимость менее 0,01).</p>

<p>Следовательно, моделируемые взаимосвязи не являются согласованными (либо из-за нестационарности, либо гетероскедастичности). Мы должны полагаться на <span class="monospace">надежные вероятности (robust_pr)</span> для определения значимости коэффициента и на <span class="monospace">статистику Вальда</span>  для определения общей значимости модели.</p>


<p><span class="monospace">Wald Test (Coefficients’ Test)|Тест Вальда (Тест коэффициентов)</span>. Если тест отклоняет нулевую гипотезу (значение <span class="monospace">P</span> меньше уровня значимости), то мы принимаем, что коэффициент <strong>b</strong> не равен нулю, и, таким образом, мы можем включить соответствующую переменную в модель. Если нулевая гипотеза не отвергнута, то удаление соответствующей переменной существенно не повредит эффективности модели.</p>

<p><span class="monospace">Тест Вальда</span> может быть дополнительно применен для проверки совместной значимости нескольких коэффициентов, и именно поэтому он также называется совместным (joined) тестом Вальда. <span class="monospace">Тест Вальда</span> следует проверять вместо <span class="monospace">F-значимости</span>, когда <span class="monospace">статистика Кенкера</span> (АД) статистически значима.  Если значение <span class="monospace">P</span> невелико, это свидетельствует о высокой общей производительности модели.</p>

<p>В нашей модели <a href="#LS Results">(Рис. 6. 16)</a> <span class="monospace">Joint Wald Statistic [e]</span> равен <span class="greencursiv">6390,163513</span>	при  Prob(>chi-squared <span class="greencursiv">0,000000*</span>, т.е.,  модель обладает достаточно высокой производительностью и мы принимаем общую значимость модели с высоким <span class="monospace">Коэффициентом Детерминации Adjusted R<sup>2</sup> [d]</span> равным согласно <span class="monospace">OLS Diagnostics</span> <span class="greencursiv">0,87531</span>.</p>

<p>Следующий <strong>третий раздел PDF-отчета</strong> <span class="monospace">Variable Distributions and Relationships|Распределение и Взаимосвязи Переменных</span> включает <span class="monospace">Диаграммы Рассеяния</span>. Каждая диаграмма рассеяния отображает взаимосвязь между объясняющей переменной и зависимой переменной. Сильные связи отображаются в виде диагоналей, а направление наклона указывает, является ли связь положительной или отрицательной. По замыслу ESRI <a href="BIBLIO.html#Bajjali_2018">[Bajjali, 2018]</a> диаграммы позволяют обнаружить какие-либо нелинейные взаимосвязи, хотя, разумеется это можно (и нужно) делать на стадии <span class="monospace">Исследовательского Анализа Данных</span>. Графики раздела представляют собой гистограммы и диаграммы рассеяния для каждой пары объясняющей  и зависимой переменных <a href="BIBLIO.html#Graf_Poor.png">(Рис. 6.18)</a>. Гистограммы показывают, как распределена каждая переменная. <span class="monospace">OLS</span> не требует, чтобы переменные были нормально распределены,  если возникают проблемы с поиском правильно заданной модели, можно попробовать преобразовать сильно искаженные переменные, чтобы увидеть, получите ли вы лучший результат.</p>
<br>

<div class="script_01">
<picture>
<a id="Graf_Poor.png"><img src="Pict_1_6/Graf_Poor.png" width="90%" height="80%"></a>
</picture>
<picture>
<a id="Graf_Bachel"><img src="Pict_1_6/Graf_Bachel.png" width="90%" height="80%"></a>
</picture>
<picture>
<a id="Graf_Footpnt"><img src="Pict_1_6/Graf_Footpnt.png" width="90%"height="80%"></a>
</picture>
</div>

<div class="script_01">
<picture>
<a id="Graf_Income."><img src="Pict_1_6/Graf_Income.png" width="90%" height="80%"></a>
</picture>
<picture>
<a id="Graf_GininInd"><img src="Pict_1_6/Graf_GininInd.png" width="90%" height="80%"></a>
</picture>
<picture>
<a id="Graf_MedianAge"><img src="Pict_1_6/Graf_MedianAge.png" width="90%" height="80%"></a>
</picture>
</div><br>

<span class="imgtitle">Рис. 6.18 Гистограммы и Диаграммы Рассеяния для каждой объясняющей переменной и зависимой переменной в PDF отчете, слева направо верхний ряд - Доля домохозяйств ниже уровня бедности, Доля лиц со степенью бакалавра, Объемный след; нижний ряд -  Среднегодовой доход домохозяйств, Индекс неравенства доходов Джини, Средний возраст жителей

<p>Далее в PDF-отчете приведена <span class="monospace">Histogram of Standardized Residuals|Гистограмма стандартизированных Остатков</span>, сопровождающаяся следующей справкой <i>"В идеале гистограмма ваших остатков должна соответствовать нормальной кривой, указанной выше синим цветом. Если гистограмма сильно отличается от нормальной кривой, возможно, у вас предвзятая модель. Если это смещение является значительным, оно также будет представлено статистически значимым <span class="monospace">P-значением Jarque-Bera(*)</span>"</i>.</p>
<br>

<a id="Histogram of Standardized Residuals"><img src="Pict_1_6/Histogram of Standardized Residuals.png" width="50%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.19 Гистограмма стандартизированных остатков

<p><strong>Заключительный раздел PDF-отчета</strong> <span class="monospace">Метода Наименьших Квадратов</span> содержит  два графика. График <span class="monospace">Received Residual vs. Predicted Residual (Полученных Остатков против Ожидаемых Остатков)</span>: значения выше и ниже прогнозируемых по отношению к  значениям зависимых переменных.</p>
<br>

<div class="script_01">
<figure>
<a id="Residual vs Predicted Plot"><img src="Pict_1_6/Residual vs Predicted Plot.png" width="270" height="270"></a>
</figure>
<figure>
<a id="Random Residuals"><img src="Pict_1_6/Random Residuals.png" width="270" height="270"></a>
</figure>
</div><br>

<span class="imgtitle">Рис. 6.20 График Полученных Остатков против Ожидаемых и график Рандомных Остатков (для сравнения)

<p>График сопровождается "подсказкой": <i>"Для правильно заданной модели эта диаграмма рассеяния будет иметь небольшую структуру и выглядеть случайной. Если в этом сюжете есть структура, тип структуры может быть ценным ключом, который поможет вам понять, что происходит"</i>. В нашей модели <a href="#Random Residuals">(Рис. 6.20)</a> явно прослеживается искажение, свидетельствующее о нелинейном характере связи между зависимой переменной и предикторами.</p>
<br>`

<a id="OLS7values"><img src="Pict_1_6/OLS7values.png" width="65%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.21 Картограмма стандартизированных остатков

<p>Мы можем верифицировать наши выводы и по <span class="monospace">Картограмме Стандартизированных Остатков</span>, являющейся вторым (кроме PDF-отчета) результатом работы инструмента <span class="monospace">OLS regression</span>. Особое внимание следует обратить на распределение кварталов, характеризующихся более чем <span class="greencursiv">2,5</span> стандартными отклонениями в большую или меньшую сторону (такие полигоны закрашиваются в ярко-красный и синий цвета соответственно)</p>

<p>В качестве дополнительной процедуры мы можем подвергнуть векторный слой <span class="monospace">Стандартизированных Остатков</span> проверке инструментом <span class="monospace">Пространственная автокорреляция Морана I</span> с предварительным созданием файла пространственных весов.</p>

<div class="script">
ArcToolBox >> Spatial Statistics Tools >> Modeling Spatial Relationships >> Generate Spatial Weights Matrix <br>
Input Feature Class: ... OLS7values<br>
Unique ID Field: ID<br>
Output Spatial Weights Matrix File: ... SW_OLS7.swm<br>
Conceptualization of Spatial Relationships: K_NEAREST_NEIGHBORS<br>
Distance Method: EUCLIDEAN<br>
Number of Neighbors: 8<br>
Row Standardization: Check<br>
OK
</div>

<p>Далее рассчитываем <span class="monospace">Пространственную Автокорреляцию Морана|Spatial Autocorrelation (Morans I)</span>:

<div class="script">	
ArcToolbox >> Spatial Statistic Tools >> Analyzing Patterns >Spatial Autocorrelation (Morans I)<br>
Input Feature Class: OLS7values <br>
Input Field: Residual<br>
Generate Report: Check<br>
Conceptualization of Spatial Relationships: GET_SPATIAL_WEIGHTS_FROM_FILE<br>
Weights Matrix File: ... SW_OLS7.swm<br>
OK
</div>

Результаты Пространственной Автокорреляции Морана: <br>

<span class="monospace">
Moran's Index:   0,100643 <br>
Expected Index:  -0,000475 <br>
Variance:   0,000109 <br>
z-score:    9,677551 <br> 
p-value:    0,000000 <br>
</span>
<br>

<a id="SpatAutoCrrellMoraNResidials"><img src="Pict_1_6/SpatAutoCrrellMoraNResidials.png" width="60%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.22 График распределение P-значения и Z-оценки для  Пространственной Автокорреляции остатков 

<p>"Подсказка" свидетельствует: <i>Учитывая z-балл <span class="greencursiv">9,67755093533</span>, вероятность того, что этот кластеризованный шаблон может быть результатом случайной случайности, составляет менее <span class="greencursiv">1%.</span></i> Иными словами, наши остатки имеют выраженное кластерное распределение</p>

<p>Подведем итоги в виде таблицы - своего рода алгоритма для сверки полученных результатов. Формально мы можем считать результатом регрессионного анализа используя следующую формулу регрессии - она следует из значений коэффициентов - столбец (a) <span class="monospace">Summary of OLS Results - Model Variables:</span><br></p>
<span class="monospace">
Y = 0,687 + 0 FOOTPRNT + 0,056 POOR + 2,61 GINI + 0,0008 BACHEL + 0,124 AFROAMUNEPL - 0,028 MEDIANAGE - 0,01 INCOME<br>
</span>
<p>Очевидно, что из этой модели без ущерба для результата можно исключить Объемный след застройки <span class="monospace">FOOTPRNT</span> и Долю лиц со степенью бакалавра <span class="monospace">BACHEL</span></p>

 Таблица 6.3 Матрица для сверки результатов регрессионного анализа

<div class="table">
<table id="customers">
        <table border="1">
	
<tr>
      <th>Индикаторы</th>
      <th>Значение</th>
      <th>Значимость</th>
      <th>Интерпретация</th>
      <th>Примечание</th>
</tr>
<tr>
		<td>R-Squared:<br>Общая состоятельность<br> модели</td>
		<td>0,8757 (+) </td>
		<td> ---- </td>
		<td>Модель объясняет 87,6 % вариации зависимой переменной Murdr5y</td>
		<td>Следует проверить Скорректированный R-квадрат</td>
</tr>
<tr>
		<td>Adjusted<br>R-Squared:<br> Общая состоятельность <br>модели</td>
		<td>0,8753 (+) </td>
		<td> ---- </td>
		<td>Скорректированный R-квадрат равен 0,8753, что указывает на высокую степень подгонки,  еще одно подтверждение, что Модель объясняет 87,5 %вариации зависимой переменной</td>
		<td>Необходимость добавления дополнительных переменных для лучшей подгонки модели отсутствует</td>
</tr>
<tr>
		<td>Joint F-Statistic<br>: Совместная<br> F-статистика </td>
		<td>2114,1 (+)</td>
		<td>0,000000* (тест значим на  уровне 0,01)</td> 
		<td>Нулевая гипотеза отвергается,  регрессионная модель статистически значима: тенденция является реальным эффектом, а не результатом случайной выборки данных</td>
		<td>Необходима дополнительная перепроверка с помощью совместной статистики Вальда, особенно если тест Кенкера (КБ) является статистически значимым</td>
</tr>
<tr>
		<td>Joint Wald Statistic<br> Совместная<br> Статистика Вальда</td>
		<td>6390,2 (+) </td>
		<td>0,000000* (тест значим уровне 0,01)</td>
		<td>Совместный тест Вальда статистически значим и подтверждает  общую валидность модели</td>
		<td>статистика Вальда использована для анализа общей производительности модели, поскольку  Koenker (BP) Statistic [f] статистически значима (р <0,05)</td>
</tr>
<tr>
		<td>Akaike's Information<br> Criterion (AICc)<br> Акайке Исправленный критерий(AICC)</td>
		<td>6913,2 (+) </td>
		<td> ---- </td>
		<td>AICc — это  показатель качества моделей для одного и того же набора данных, AICcуказывает на лучшее соответствие, когда значения уменьшаются.</td>
		<td>Может быть использован для изменения набора переменных, сравнения различных моделей и выбора наиболее подходящей</td>
</tr>
<tr>
			<td>Coefficient [a] <br> бета-коэффициенты<br> - множители переменных</td>
			<td>Probability [b]: <br>
				FOOTPRNT   0  					0,000234*<br>
 				POORSQRT   0,055686   	0,000000*<br>
				GINI_LG    2,610726			0,000000* <br>
				BACHSQRT   0,000851			0,742836 <br>
				AFRUNMPLOY 0,123641 		0,000000*<br>
				MEDIANAGE	 -0,027613	 	0,000000*<br>
				INCOME     -0,010632 		0,000000*	<br>		
			</td>
			<td>Значима на  уровне,  не превышающем 0,01</td>
			<td>Все переменные значимы, за исключением BACHSQRT, знаки коэффициентов совпадают с ожиданиями </td>
			<td>Поскольку статистика Koenker (BP) статистически значима, в оценке достоверности значений бета-коэффициентов необходимо использовать надежные вероятности \ robust probabilities (Probability [b]); переменную Доля лиц со степенью бакалавра можно исключить из модели </td>
</tr>			
<tr>
			<td>Coefficients <br>t-statistic <br> Коэффициенты <br>t-статистика</td>
			<td>Probability [b]:
				FOOTPRNT 0,000234*
 				POORSQRT 0,000000*
				GINI_LG  0,000000* 
				BACHSQRT  0,742836 
				AFRUNMPLOY  0,000000*
				MEDIANAGE	0,000000*
				INCOME 0,000000*			</td>
			<td>Значима на  уровне  не превышающем 0,01</td>
			<td>Все переменные значимы, за исключением BACHSQRT </td>
			<td>Поскольку статистика Koenker (BP) статистически значима, вместо этого привлечены надежные вероятности \ robust probabilities (Probability [b]); переменную Доля лиц со степенью бакалавра можно исключить из модели </td>
</tr>
<tr>
			<td>Standard Errors <br>(Robust probabilites)
 Cтандартные Ошибки (надежные вероятности)</td>
			<td>Robust_Pr [b]:
				FOOTPRNT 00,000184*
 				POORSQRT 0,000000*
				GINI_LG  0,000001*
 				BACHSQRT  0,724484
 				AFRUNMPLOY  0,000000*
				MEDIANAGE	0,000000*
				INCOME 0,000000*</td>
			<td>Значима на  уровне  не превышающем 0,01</td>
			<td>Все переменные значимы, за исключением BACHSQRT</td>
			<td>Шесть переменных с коэффициентами Std. Err. (Robust probabilites), прошедшими тест могут считаться устойчивыми к гетероскедастичности </td>
</tr>
<tr>
			<td>Variance Inflator <br>Factor|Мультиколлинеарность</td>
			<td>VIF:
				FOOTPRNT 1,101646
 				POORSQRT 1,369942
				GINI_LG  1,189733
 				BACHSQRT  1,632422
 				AFRUNMPLOY  1,405973
				MEDIANAGE	1,200341
				INCOME 1,734695</td>
			<td>VIF: 1-4 коллинеарность отсутствует<br>
			VIF: 4-10 требуется дополнительный анализ<br>
			VIF > 10 наблюдается значительная коллинеарность<br> </td>
			<td>Все переменные имеют значения меньше, чем 4; отсутствие проблем с мультиколлинеарностью</td>
			<td>К модели не следует добавлять дополнительные переменные, из уже привлеченных чуть более высокое значение имеют INCOME и BACHSQRT - возможные кандидаты на удаление</td>
</tr>
<tr>
			<td>Normality of residual <br>errors Jarque–Bera|<br>Статистика Жарка-Бера Нормальность остаточных  ошибок </td>
			<td>3524,8 Prob(>chi-squared), (2) degrees of freedom:	0,000000*</td>
			<td>Значим на  уровне 0,01<br> </td>
			<td>Нулевая гипотеза (нормальность ошибок) должна быть отвергнута, поскольку значение теста статистически значимо.</td>
			<td>Предвзятая модель с нарушенные условием  о нормальности ошибок, возможно также что в модели не хватает одной или нескольких ключевых переменных</td>
</tr>
<tr>
			<td>Heteroscedasticity <br>Koenker–Bassett test<br>|Гетероскедастичность тест Кенкера</td>
			<td>0,000000*</td>
			<td>Значим на  уровне 0,01<br> </td>
			<td>Нулевая гипотеза (гомоскедастичность) должна быть отвергнута, поскольку значение теста статистически значимо</td>
			<td>Взаимоотношения зависимой переменной через предложенные коэффициенты (Coefficient [a]) не являются согласованными; отношения между
некоторыми или всеми  объясняющими переменными и  зависимой переменной нестационарны) </td>
</tr>
<tr>
			<td>Spatial Dependence<br> Moran’s I</td>
			<td>0,100643</td>
			<td>Значим на  уровне 0,01<br> </td>
			<td>Не значимы</td>
			<td>Отсутствуют достаточные основания для опровержения гипотезы об отсутствии пространственной автокорреляции</td>
			
</table>

<p>Таким образом, по результатам анализа мы можем как минимум - скорректировать нашу модель:</p>

<span class="monospace">
Y: 0,687 +  0,056 POOR + 2,61 GINI  + 0,124 AFROAMUNEPL - 0,028 MEDIANAGE - 0,01 INCOME<br>
</span>
<p>Модель не прошла тестирование по двум важными параметрам <span class="monospace">тесту Кренкера</span> и <span class="monospace">тесту Жарка-Барра</span>. Когда <span class="monospace">тест Кенкера</span> статистически значим, как здесь, это указывает, что отношения между некоторыми или всеми  объясняющими переменными и  зависимой переменной нестационарны. Например,  переменная Индекс Джини может быть важным предиктором количества  тяжких преступлений в некоторых кварталах Нью-Йорка, но, возможно, слабым предиктором в других местах. В этих случаях рекомендуется улучшить результат модели, перейдя к географически взвешенной регрессии.</p>
<br>
			
		<h3 id="h3_5">6.5. Географически взвешенная регрессия</h3>

<p>Необходимость (и возможность) использования <span class="monospace">Географически Взвешенной Регрессии GWR</span> для данного набора данных объясняется значимостью тест Кенкера или  гетероскедастичностью. В процедуре GWR можно использовать оптимизированный набор переменных удалив из него - согласно результатам <span class="monospace">OLS</span>  - показатель не прошедший два важных теста - <span class="monospace">Долю лиц со степенью бакалавра</span>. В итоге для объяснения зависимой переменной - числа тяжких преступлений в кварталах Нью-Йорка у нас остается шесть факторов. Интерфейс инструмента <span class="monospace">GWR</span> несколько отличается от двух предыдущих видов регрессии</p>

<div class="script">
ArcToolbox >> Spatial Statistic Tools >> Modeling Spatial Relationships >> Geographically Weighted Regression<br>
Input Feature Class: NYCTRACTs <br>
Dependent Variable: Murdr15y<br>
Explanatory Variable: poorsqrt, ... medianage (*6 переменных)<br>
Output Feature Class: ... GWR4values.shp<br>
Kernel Type: ADAPTIVE<br>
Bandwidth method: BANDWIDTH_PARAMETER<br>
Weights: Mudr_15y<br>
Coefficient raster workspace: ... 2020 Census Tracts - Tabular<br>
Leave all other fields blank or as filled by default<br>
OK
</div>

<p><span class="monospace">Географически Взвешенная Регрессия</span>, реализованная в <span class="red">ArcMAP10.x</span>, дает три основных раздела:  (А) общая диагностика, (Б) выходной класс объектов (шейп-файл), содержащий все локальные оценки, (В) растровые поверхности коэффициентов, отображающие каждый коэффициент отдельно.</p>

<p>Начнем с анализа дополнительной таблицы <span class="monospace">GWR_supp.dbf</span>, в которой представлены основные результаты модели: 

<div class="script">
ACTION: Add GWR_supp to the TOC (*добавляем таблицу к Таблицы Слоев)<br>
ArcCatalog >> Navigate to ....GWR4values_supp.dbf >> Drag and  drop WR4values_supp.dbf to the TOC<br>
TOC >> RC GWR_supp >> Open (* открываем таблице dbf по правому клику)<br>
</div>

<p>Интерпретация результатов <span class="monospace">Географически Взвешенной Регрессии</span> проводится на фоне уже полученных показателей <span class="monospace">Метода Наименьших Квадратов</span>, тем более что содержание статистик и их роль в описании успешности\неудачности модели нам известна. Проверим основные показатели.</p>

<span class="monospace">
Коэффициент Детерминации модели R<sup>2</sup> = <span class="greencursiv">0,966341</span> (0,875731 OLS)<br> 
Скорректированный Adjusted R-Squared = <span class="greencursiv">0,944978</span> (0,875310 OLS)<br> 
</span>

<p>Модель <span class="monospace">GWR</span> объясняет  около <span class="greencursiv">95%</span> вариации зависимой переменной, что на <span class="greencursiv">7%</span> выше (собственно R<sup>2</sup> лучше на <span class="greencursiv">9%</span>. Ликвидация двух вроде значимых переменных только оптимизировала модель). <span class="monospace">Акайке  критерий (AICc) </span>равен <span class="greencursiv">57,17</span> (6913,2 OLS) - в этом важном показателе мы значительно улучшили модель.</p>

<a id="GWR_dbf"><img src="Pict_1_6/GWR_dbf.png" width="50%" height="relative"></a><br>
<span class="imgtitle">Рис. 6.23 Основные результаты модели GWR  GWR_supp.dbf 

<p>Проверим <span class="monospace">Отображение стандартизированных остатков </span>(Выходной класс объектов шейп-файла):</p>

<span class="monospace">
ACTION: Add GWR_supp to the TOC (*добавляем шейм стандартизированных остатков к таблице слоев)<br>
ArcCatalog >> Navigate to ....GWR4values.shp >> Add to Display<br>
TOC >> GWR4values.shp >> Open (*открываем шейп-файл).</p>
</span>
<p>Сравним распределение остатков для OLS и GWR</p> 

<div class="script_01">
<figure>
<a id="OLS7values"><img src="Pict_1_6/OLS7values.png" width="98%" height="relative"></a>
</figure>
<figure>
<a id="GWR_4values"><img src="Pict_1_6/GWR_4values.png" width="98%" height="relative"></a>
</figure>
</div><br>

<span class="imgtitle">Рис. 6.24 Картограммы стандартизированных остатков OLS  и GWR

<p>Вспоминаем, что <span class="monospace">стандартизированные остатки</span> показывают, какая часть вариаций пространственных данных не объясняется независимыми переменными.  Как можно видеть на <span class="monospace">Картограмме GWR</span> завышенные (синие) и заниженные (красные) остатки не образуют выраженных кластеров, и в целом их распределение выглядит в большей (чем на OLS) мере случайным. Таким образом, использование <span class="blackbold">Географически взвешенной регрессии</span> позволяет оптимизировать модель и в отношении стандартизированных остатков.</p>

<p>Регрессионный анализ, используемый для выявления зависимостей между изучаемым феноменом и объясняющими переменными - нетривиальная процедура, требующее терпения и экспертных решений практически на каждом шагу. Сила алгоритма - в неплохо отработанных и более-менее ясно интерпретируемых этапах. <span class="bolditalic">Основная слабость  Регрессионного анализа заключается в том обстоятельстве, что линейные зависимости сравнительно редко встречаются как в природных, так и социальных процессах и явлениях</span>. Поэтому в последние годы в самых разных сферах геопространственного анализа создаются специальные инструменты для исследования сложных нелинейных зависимостей.</p>

<br>
			

<footer id="main-footer">Пространственный анализ в геоэкологии &copy; Е.Ю.Колбовский, 2022 </footer>
</div class="content">
</body>
</html>